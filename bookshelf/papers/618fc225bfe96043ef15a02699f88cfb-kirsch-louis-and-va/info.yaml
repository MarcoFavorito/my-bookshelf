abstract: Biological evolution has distilled the experiences of many learners into
  the general learning algorithms of humans. Our novel meta reinforcement learning
  algorithm MetaGenRL is inspired by this process. MetaGenRL distills the experiences
  of many complex agents to meta-learn a low-complexity neural objective function
  that decides how future individuals will learn. Unlike recent meta-RL algorithms,
  MetaGenRL can generalize to new environments that are entirely different from those
  used for meta-training. In some cases, it even outperforms human-engineered RL algorithms.
  MetaGenRL uses off-policy second-order gradients during meta-training that greatly
  increase its sample efficiency.
archiveprefix: arXiv
author: Kirsch, Louis and van Steenkiste, Sjoerd and Schmidhuber, Jürgen
author_list:
- family: Kirsch
  given: Louis
- family: van Steenkiste
  given: Sjoerd
- family: Schmidhuber
  given: Jürgen
eprint: 1910.04098v2
file: 1910.04098v2.pdf
files:
- kirsch-louis-and-van-steenkiste-sjoerd-and-schmidhuber-jurgenimproving-generalization-in-meta-reinforcement-learning-using-learned-objectives2019.pdf
month: Oct
primaryclass: cs.LG
ref: 1910.04098v2
time-added: 2020-11-11-09:34:54
title: Improving Generalization in Meta Reinforcement Learning using Learned   Objectives
type: article
url: http://arxiv.org/abs/1910.04098v2
year: '2019'
