abstract: 'Model-based reinforcement learning (MBRL) is widely seen as having the
  potential to be significantly more sample efficient than model-free RL. However,
  research in model-based RL has not been very standardized. It is fairly common for
  authors to experiment with self-designed environments, and there are several separate
  lines of research, which are sometimes closed-sourced or not reproducible. Accordingly,
  it is an open question how these various existing MBRL algorithms perform relative
  to each other. To facilitate research in MBRL, in this paper we gather a wide collection
  of MBRL algorithms and propose over 18 benchmarking environments specially designed
  for MBRL. We benchmark these algorithms with unified problem settings, including
  noisy environments. Beyond cataloguing performance, we explore and unify the underlying
  algorithmic differences across MBRL algorithms. We characterize three key research
  challenges for future MBRL research: the dynamics bottleneck, the planning horizon
  dilemma, and the early-termination dilemma. Finally, to maximally facilitate future
  research on MBRL, we open-source our benchmark in http://www.cs.toronto.edu/~tingwuwang/mbrl.html.'
archiveprefix: arXiv
author: Wang, Tingwu and Bao, Xuchan and Clavera, Ignasi and Hoang, Jerrick and Wen,
  Yeming and Langlois, Eric and Zhang, Shunshi and Zhang, Guodong and Abbeel, Pieter
  and Ba, Jimmy
author_list:
- family: Wang
  given: Tingwu
- family: Bao
  given: Xuchan
- family: Clavera
  given: Ignasi
- family: Hoang
  given: Jerrick
- family: Wen
  given: Yeming
- family: Langlois
  given: Eric
- family: Zhang
  given: Shunshi
- family: Zhang
  given: Guodong
- family: Abbeel
  given: Pieter
- family: Ba
  given: Jimmy
eprint: 1907.02057v1
file: 1907.02057v1.pdf
files:
- wang-tingwu-and-bao-xuchan-and-clavera-ignasi-and-hoang-jerrick-and-wen-yeming-and-langlois-eric-and-zhang-shunshi-and-zhang-guodong-and-abbee.pdf
month: Jul
primaryclass: cs.LG
ref: 1907.02057v1
time-added: 2020-12-02-16:56:00
title: Benchmarking Model-Based Reinforcement Learning
type: article
url: http://arxiv.org/abs/1907.02057v1
year: '2019'
