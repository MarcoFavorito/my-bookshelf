<!DOCTYPE html>
<html lang="en" class="no-js">
<head>
    <meta charset="UTF-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="access" content="Yes">

    

    <meta name="twitter:site" content="@SpringerLink"/>

    <meta name="twitter:card" content="summary"/>

    <meta name="twitter:image:alt" content="Content cover image"/>

    <meta name="journal_id" content="10898"/>

    <meta name="dc.title" content="When is there a representer theorem?"/>

    <meta name="dc.source" content="Journal of Global Optimization 2019 74:2"/>

    <meta name="dc.format" content="text/html"/>

    <meta name="dc.publisher" content="Springer"/>

    <meta name="dc.date" content="2019-04-08"/>

    <meta name="dc.type" content="OriginalPaper"/>

    <meta name="dc.language" content="En"/>

    <meta name="dc.copyright" content="2019 The Author(s)"/>

    <meta name="dc.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="dc.description" content="We consider a general regularised interpolation problem for learning a parameter vector from data. The well known representer theorem says that under certain conditions on the regulariser there exists a solution in the linear span of the data points. This is at the core of kernel methods in machine learning as it makes the problem computationally tractable. Necessary and sufficient conditions for differentiable regularisers on Hilbert spaces to admit a representer theorem have been proved. We extend those results to nondifferentiable regularisers on uniformly convex and uniformly smooth Banach spaces. This gives a (more) complete answer to the question when there is a representer theorem. We then note that for regularised interpolation in fact the solution is determined by the function space alone and independent of the regulariser, making the extension to Banach spaces even more valuable."/>

    <meta name="prism.issn" content="1573-2916"/>

    <meta name="prism.publicationName" content="Journal of Global Optimization"/>

    <meta name="prism.publicationDate" content="2019-04-08"/>

    <meta name="prism.volume" content="74"/>

    <meta name="prism.number" content="2"/>

    <meta name="prism.section" content="OriginalPaper"/>

    <meta name="prism.startingPage" content="401"/>

    <meta name="prism.endingPage" content="415"/>

    <meta name="prism.copyright" content="2019 The Author(s)"/>

    <meta name="prism.rightsAgent" content="journalpermissions@springernature.com"/>

    <meta name="prism.url" content="https://link.springer.com/article/10.1007/s10898-019-00767-0"/>

    <meta name="prism.doi" content="doi:10.1007/s10898-019-00767-0"/>

    <meta name="citation_pdf_url" content="https://link.springer.com/content/pdf/10.1007/s10898-019-00767-0.pdf"/>

    <meta name="citation_fulltext_html_url" content="https://link.springer.com/article/10.1007/s10898-019-00767-0"/>

    <meta name="citation_journal_title" content="Journal of Global Optimization"/>

    <meta name="citation_journal_abbrev" content="J Glob Optim"/>

    <meta name="citation_publisher" content="Springer US"/>

    <meta name="citation_issn" content="1573-2916"/>

    <meta name="citation_title" content="When is there a representer theorem?"/>

    <meta name="citation_volume" content="74"/>

    <meta name="citation_issue" content="2"/>

    <meta name="citation_publication_date" content="2019/06"/>

    <meta name="citation_online_date" content="2019/04/08"/>

    <meta name="citation_firstpage" content="401"/>

    <meta name="citation_lastpage" content="415"/>

    <meta name="citation_article_type" content="Article"/>

    <meta name="citation_fulltext_world_readable" content=""/>

    <meta name="citation_language" content="en"/>

    <meta name="dc.identifier" content="doi:10.1007/s10898-019-00767-0"/>

    <meta name="DOI" content="10.1007/s10898-019-00767-0"/>

    <meta name="citation_doi" content="10.1007/s10898-019-00767-0"/>

    <meta name="description" content="We consider a general regularised interpolation problem for learning a parameter vector from data. The well known representer theorem says that under certa"/>

    <meta name="dc.creator" content="Kevin Schlegel"/>

    <meta name="dc.subject" content="Optimization"/>

    <meta name="dc.subject" content="Operations Research/Decision Theory"/>

    <meta name="dc.subject" content="Real Functions"/>

    <meta name="dc.subject" content="Computer Science, general"/>

    <meta name="citation_reference" content="citation_journal_title=J. Mach. Learn. Res.; citation_title=When is there a representer theorem? vector versus matrix regularizers; citation_author=A Argyriou, CA Micchelli, M Pontil; citation_volume=10; citation_publication_date=2009; citation_pages=2507-2529; citation_id=CR1"/>

    <meta name="citation_reference" content="citation_title=Functional Analysis, Sobolev Spaces and Partial Differential Equations; citation_publication_date=2011; citation_id=CR2; citation_author=H Brezis; citation_publisher=Springer"/>

    <meta name="citation_reference" content="citation_journal_title=Ann. Stat.; citation_title=Asymptotic analysis of penalized likelihood and related estimators; citation_author=DD Cox, F O&#8217;Sullivan; citation_volume=18; citation_issue=4; citation_publication_date=1990; citation_pages=1676-1695; citation_doi=10.1214/aos/1176347872; citation_id=CR3"/>

    <meta name="citation_reference" content="citation_journal_title=Bull. Am. Math. Soc.; citation_title=On the mathematical foundations of learning; citation_author=F Cucker, S Smale; citation_volume=39; citation_issue=1; citation_publication_date=2001; citation_pages=1-49; citation_doi=10.1090/S0273-0979-01-00923-5; citation_id=CR4"/>

    <meta name="citation_reference" content="citation_title=Semi-inner Products and Applications; citation_publication_date=2004; citation_id=CR5; citation_author=SS Dragomir; citation_publisher=Nova Science Publishers"/>

    <meta name="citation_reference" content="citation_journal_title=Trans. Am. Math. Soc.; citation_title=Classes of semi-inner-product spaces; citation_author=JR Giles; citation_volume=129; citation_issue=3; citation_publication_date=1967; citation_pages=436-446; citation_doi=10.1090/S0002-9947-1967-0217574-1; citation_id=CR6"/>

    <meta name="citation_reference" content="citation_journal_title=Trans. Am. Math. Soc.; citation_title=Orthogonality and linear functionals in normed linear spaces; citation_author=RC James; citation_volume=61; citation_issue=2; citation_publication_date=1947; citation_pages=265-292; citation_doi=10.1090/S0002-9947-1947-0021241-4; citation_id=CR7"/>

    <meta name="citation_reference" content="citation_journal_title=J. Math. Anal. Appl.; citation_title=Some results on Tchebycheffian spline functions; citation_author=G Kimeldorf, G Wahba; citation_volume=33; citation_issue=1; citation_publication_date=1971; citation_pages=82-95; citation_doi=10.1016/0022-247X(71)90184-3; citation_id=CR8"/>

    <meta name="citation_reference" content="citation_title=Topological Vectorspaces I, Grundlehren der Mathematischen Wissenschaften; citation_publication_date=1983; citation_id=CR9; citation_author=G K&#246;the; citation_publisher=Springer"/>

    <meta name="citation_reference" content="citation_title=Classical Banach Spaces II: Function Spaces, Ergebnisse der Mathematik und ihrer Grenzgebiete; citation_publication_date=1979; citation_id=CR10; citation_author=J Lindenstrauss; citation_author=L Tzafriri; citation_publisher=Springer"/>

    <meta name="citation_reference" content="citation_journal_title=Trans. Am. Math. Soc.; citation_title=Semi-inner-product spaces; citation_author=G Lumer; citation_volume=100; citation_issue=1; citation_publication_date=1961; citation_pages=29-43; citation_doi=10.1090/S0002-9947-1961-0133024-2; citation_id=CR11"/>

    <meta name="citation_reference" content="citation_title=A function representation for learning in banach spaces; citation_inbook_title=Learning Theory; citation_publication_date=2004; citation_pages=255-269; citation_id=CR12; citation_author=CA Micchelli; citation_author=M Pontil; citation_publisher=Springer"/>

    <meta name="citation_reference" content="citation_journal_title=J. Mach. Lear. Res.; citation_title=Learning the kernel function via regularization; citation_author=CA Micchelli, M Pontil; citation_volume=6; citation_publication_date=2005; citation_pages=1099-1125; citation_id=CR13"/>

    <meta name="citation_reference" content="citation_title=A generalized representer theorem; citation_inbook_title=Computational Learning Theory; citation_publication_date=2001; citation_pages=416-426; citation_id=CR14; citation_author=B Sch&#246;lkopf; citation_author=R Herbrich; citation_author=AJ Smola; citation_publisher=Springer"/>

    <meta name="citation_reference" content="citation_title=Learning with Kernels; citation_publication_date=2002; citation_id=CR15; citation_author=B Sch&#246;lkopf; citation_author=AJ Smola; citation_publisher=MIT Press"/>

    <meta name="citation_reference" content="citation_title=Kernel Methods for Pattern Analysis; citation_publication_date=2004; citation_id=CR16; citation_author=J Shawe-Taylor; citation_author=N Cristianini; citation_publisher=Cambridge University Press"/>

    <meta name="citation_reference" content="citation_journal_title=Algorithmica; citation_title=On a kernel-based method for pattern recognition, regression, approximation, and operator inversion; citation_author=JA Smola, B Sch&#246;lkopf; citation_volume=22; citation_issue=1; citation_publication_date=1998; citation_pages=211-231; citation_doi=10.1007/PL00013831; citation_id=CR17"/>

    <meta name="citation_reference" content="citation_journal_title=J. Mach. Learn. Res.; citation_title=reproducing kernel banach spaces for machine learning; citation_author=H Zhang, Y Xu, J Zhang; citation_volume=10; citation_publication_date=2009; citation_pages=2741-2775; citation_id=CR18"/>

    <meta name="citation_reference" content="citation_journal_title=J. Global Optim.; citation_title=Regularized learning in banach spaces as an optimization problem: representer theorems; citation_author=H Zhang, J Zhang; citation_volume=54; citation_issue=2; citation_publication_date=2012; citation_pages=235-250; citation_doi=10.1007/s10898-010-9575-z; citation_id=CR19"/>

    <meta name="citation_author" content="Kevin Schlegel"/>

    <meta name="citation_author_email" content="schlegel@maths.ox.ac.uk"/>

    <meta name="citation_author_institution" content="Mathematical Institute, University of Oxford, Oxford, UK"/>

    <meta name="citation_springer_api_url" content="http://api.springer.com/metadata/pam?q=doi:10.1007/s10898-019-00767-0&amp;api_key="/>

    <meta name="format-detection" content="telephone=no"/>

    <meta name="citation_cover_date" content="2019/06/01"/>


    
        <meta property="og:url" content="https://link.springer.com/article/10.1007/s10898-019-00767-0"/>
        <meta property="og:type" content="article"/>
        <meta property="og:site_name" content="Journal of Global Optimization"/>
        <meta property="og:title" content="When is there a representer theorem?"/>
        <meta property="og:description" content="We consider a general regularised interpolation problem for learning a parameter vector from data. The well known representer theorem says that under certain conditions on the regulariser there exists a solution in the linear span of the data points. This is at the core of kernel methods in machine learning as it makes the problem computationally tractable. Necessary and sufficient conditions for differentiable regularisers on Hilbert spaces to admit a representer theorem have been proved. We extend those results to nondifferentiable regularisers on uniformly convex and uniformly smooth Banach spaces. This gives a (more) complete answer to the question when there is a representer theorem. We then note that for regularised interpolation in fact the solution is determined by the function space alone and independent of the regulariser, making the extension to Banach spaces even more valuable."/>
        <meta property="og:image" content="https://media.springernature.com/w110/springer-static/cover/journal/10898.jpg"/>
    

    <title>When is there a representer theorem? | SpringerLink</title>

    <link rel="shortcut icon" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16 32x32 48x48" href=/oscar-static/images/favicons/springerlink/favicon-eb9f5576a3.ico />
<link rel="icon" sizes="16x16" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-16x16-8bd8c1c945.png />
<link rel="icon" sizes="32x32" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-32x32-61a52d80ab.png />
<link rel="icon" sizes="48x48" type="image/png" href=/oscar-static/images/favicons/springerlink/favicon-48x48-0ec46b6b10.png />
<link rel="apple-touch-icon" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />
<link rel="apple-touch-icon" sizes="72x72" href=/oscar-static/images/favicons/springerlink/ic_launcher_hdpi-f77cda7f65.png />
<link rel="apple-touch-icon" sizes="76x76" href=/oscar-static/images/favicons/springerlink/app-icon-ipad-c3fd26520d.png />
<link rel="apple-touch-icon" sizes="114x114" href=/oscar-static/images/favicons/springerlink/app-icon-114x114-3d7d4cf9f3.png />
<link rel="apple-touch-icon" sizes="120x120" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@2x-67b35150b3.png />
<link rel="apple-touch-icon" sizes="144x144" href=/oscar-static/images/favicons/springerlink/ic_launcher_xxhdpi-986442de7b.png />
<link rel="apple-touch-icon" sizes="152x152" href=/oscar-static/images/favicons/springerlink/app-icon-ipad@2x-677ba24d04.png />
<link rel="apple-touch-icon" sizes="180x180" href=/oscar-static/images/favicons/springerlink/app-icon-iphone@3x-f259d46347.png />


    
    <script>(function(H){H.className=H.className.replace(/\bno-js\b/,'js')})(document.documentElement)</script>

    <link rel="stylesheet" href=/oscar-static/app-springerlink/css/core-article-b4c7d745df.css media="screen">
    <link rel="stylesheet" id="js-mustard" href=/oscar-static/app-springerlink/css/enhanced-article-a99e6e4c5c.css media="only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)">
    

    
    <script type="text/javascript">
        window.dataLayer = [{"Country":"IT","doi":"10.1007-s10898-019-00767-0","Journal Title":"Journal of Global Optimization","Journal Id":10898,"Keywords":"Representer theorem, Regularised interpolation, Regularisation, Semi-inner product spaces, Kernel methods, 68T05","kwrd":["Representer_theorem","Regularised_interpolation","Regularisation","Semi-inner_product_spaces","Kernel_methods","68T05"],"Labs":"Y","ksg":"Krux.segments","kuid":"Krux.uid","Has Body":"Y","Features":[],"Open Access":"Y","hasAccess":"Y","bypassPaywall":"N","user":{"license":{"businessPartnerID":[],"businessPartnerIDString":""}},"Access Type":"open","Bpids":"","Bpnames":"","BPID":["1"],"VG Wort Identifier":"vgzm.415900-10.1007-s10898-019-00767-0","Full HTML":"Y","Subject Codes":["SCM","SCM26008","SC521000","SCM12171","SCI00001"],"pmc":["M","M26008","521000","M12171","I00001"],"session":{"authentication":{"loginStatus":"N"},"attributes":{"edition":"academic"}},"content":{"serial":{"eissn":"1573-2916","pissn":"0925-5001"},"type":"Article","category":{"pmc":{"primarySubject":"Mathematics","primarySubjectCode":"M","secondarySubjects":{"1":"Optimization","2":"Operations Research/Decision Theory","3":"Real Functions","4":"Computer Science, general"},"secondarySubjectCodes":{"1":"M26008","2":"521000","3":"M12171","4":"I00001"}},"sucode":"SC10"},"attributes":{"deliveryPlatform":"oscar"}},"Event Category":"Article","GA Key":"UA-26408784-1","DOI":"10.1007/s10898-019-00767-0","Page":"article","page":{"attributes":{"environment":"live"}}}];
    </script>


    
    
        
            <script src=/oscar-static/js/jquery-220afd743d.js></script>
        
    

    
        <script>
    (function() {
        function deleteCookie (name, domain) {
            document.cookie = encodeURIComponent(name) +
                    '=' +
                    ';path=/' +
                    ';domain=' + domain +
                    ';expires=Thu, 01 Jan 1970 00:00:00 GMT';
        }

        var consentCookieParts = ('; ' + document.cookie).split('; OptanonConsent=');

        if (consentCookieParts.length > 1) {
            consentCookieParts.shift(); // remove redundant first part from the split array

            // onetrust can set the same cookie multiple times with different domain specificities
            for (let i=0; i<consentCookieParts.length; i++) {
                var otCookieGroups = consentCookieParts[i].split('&groups=').pop().split('&').shift();

                if (otCookieGroups.indexOf('C0001') === -1) {
                    // to be deleted when new onetrust implemented on www.springer.com pages
                    deleteCookie('OptanonConsent', '.springer.com');

                    deleteCookie('OptanonConsent', 'link.springer.com');
                    deleteCookie('OptanonAlertBoxClosed', 'link.springer.com');
                }
            }
        }
    })();
</script>
    

    <script data-test="onetrust-control">
        
            (function(w,d,t) {
                var assetPath = '/oscar-static/js/cookie-consent-es5-bundle-0ea0aa3601.js';
                function cc() {
                    var h = w.location.hostname,
                        e = d.createElement(t),
                        s = d.getElementsByTagName(t)[0];

                    if (h === "link.springer.com") {
                        e.src = "https://cdn.cookielaw.org/scripttemplates/otSDKStub.js";
                        e.setAttribute("data-domain-script", "4f53bc14-4ee3-45bd-9935-e3d2b6b2a543");
                    } else {
                        e.src = assetPath;
                        e.setAttribute("data-consent", h);
                    }
                    s.parentNode.insertBefore(e, s);
                }
                w.google_tag_manager ? cc() : window.addEventListener("gtm_loaded", cc);
            })(window,document,"script");
        
    </script>
    <script>
        function OptanonWrapper() {
            var elementInside = function(candidate, element) {
                if (candidate === element) {
                    return true;
                } else if (candidate.nodeName.toLowerCase() === 'body') {
                    return false;
                } else {
                    return elementInside(candidate.parentNode, element);
                }
            };

            var disclaimer = document.querySelector('.c-disclaimer[aria-hidden="false"]');
            window.dataLayer.push({event:'OneTrustGroupsUpdated'});
            if (disclaimer) {
                if (!elementInside(document.activeElement, disclaimer)) {
                    disclaimer.querySelector('button').focus();
                }
            } else {
                document.activeElement.blur();
            }
        }
    </script>

    <script>
    window.config = window.config || {};
    window.config.mustardcut = false;

    
    if (window.matchMedia && window.matchMedia('only screen and (-webkit-min-device-pixel-ratio:0) and (min-color-index:0), (-ms-high-contrast: none), only all and (min--moz-device-pixel-ratio:0) and (min-resolution: 3e1dpcm)').matches) {
        window.config.mustardcut = true;
    }
</script>

    <!--Polyfills CustomEvent constructor in IE. Allows us to use events to manage race conditions in client side js-->
<script>
    (function () {
        if ( typeof window.CustomEvent === "function" ) return false;
        function CustomEvent ( event, params ) {
            params = params || { bubbles: false, cancelable: false, detail: null };
            var evt = document.createEvent( 'CustomEvent' );
            evt.initCustomEvent( event, params.bubbles, params.cancelable, params.detail );
            return evt;
        }

        CustomEvent.prototype = window.Event.prototype;

        window.CustomEvent = CustomEvent;
    })();
</script>

    
    
        <!-- Google Tag Manager -->
        <script data-test="gtm-head">
            if (window.config.mustardcut) {
                (function (w, d, s, l, i) {
                    w[l] = w[l] || [];
                    w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});
                    var f = d.getElementsByTagName(s)[0],
                            j = d.createElement(s),
                            dl = l != 'dataLayer' ? '&l=' + l : '';
                    j.async = true;
                    j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
                    
                    j.addEventListener('load', function() {
                        var _ge = new CustomEvent('gtm_loaded', { bubbles: true });
                        d.dispatchEvent(_ge);
                    });
                    f.parentNode.insertBefore(j, f);
                })(window, document, 'script', 'dataLayer', 'GTM-WCF9Z9');
            }
        </script>
        <!-- End Google Tag Manager -->
    


    <script class="js-entry">
    if (window.config.mustardcut) {
        (function(w, d) {
            
            
            
                window.Component = {};
            

            var currentScript = d.currentScript || d.head.querySelector('script.js-entry');

            
            function catchNoModuleSupport() {
                var scriptEl = d.createElement('script');
                return (!('noModule' in scriptEl) && 'onbeforeload' in scriptEl)
            }

            var headScripts = [
                {'src': '/oscar-static/js/polyfill-es5-bundle-974eb189f7.js', 'async': false},
                {'src': '/oscar-static/js/airbrake-es5-bundle-afdf4df4df.js', 'async': false},
            ];

            var bodyScripts = [
                {'src': '/oscar-static/js/app-es5-bundle-05e3d0b21b.js', 'async': false, 'module': false},
                {'src': '/oscar-static/js/app-es6-bundle-8d5be091e0.js', 'async': false, 'module': true}
                
                
                    , {'src': '/oscar-static/js/global-article-es5-bundle-a09bf6a420.js', 'async': false, 'module': false},
                    {'src': '/oscar-static/js/global-article-es6-bundle-ce77ae8163.js', 'async': false, 'module': true}
                
            ];

            function createScript(script) {
                var scriptEl = d.createElement('script');
                scriptEl.src = script.src;
                scriptEl.async = script.async;
                if (script.module === true) {
                    scriptEl.type = "module";
                    if (catchNoModuleSupport()) {
                        scriptEl.src = '';
                    }
                } else if (script.module === false) {
                    scriptEl.setAttribute('nomodule', true)
                }
                if (script.charset) {
                    scriptEl.setAttribute('charset', script.charset);
                }

                return scriptEl;
            }

            for (var i = 0; i < headScripts.length; ++i) {
                var scriptEl = createScript(headScripts[i]);
                currentScript.parentNode.insertBefore(scriptEl, currentScript.nextSibling);
            }

            d.addEventListener('DOMContentLoaded', function() {
                for (var i = 0; i < bodyScripts.length; ++i) {
                    var scriptEl = createScript(bodyScripts[i]);
                    d.body.appendChild(scriptEl);
                }
            });

            // Webfont repeat view
            var config = w.config;
            if (config && config.publisherBrand && sessionStorage.fontsLoaded === 'true') {
                d.documentElement.className += ' webfonts-loaded';
            }
        })(window, document);
    }
</script>

    
    
    <link rel="canonical" href="https://link.springer.com/article/10.1007/s10898-019-00767-0"/>
    

</head>
<body class="shared-article-renderer">
    
    
    
        <!-- Google Tag Manager (noscript) -->
        <noscript data-test="gtm-body">
            <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WCF9Z9"
            height="0" width="0" style="display:none;visibility:hidden"></iframe>
        </noscript>
        <!-- End Google Tag Manager (noscript) -->
    


    <div class="u-vh-full">
        
    <aside class="c-ad c-ad--728x90" data-test="springer-doubleclick-ad">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-LB1" data-gpt-unitpath="/270604982/springerlink/10898/article" data-gpt-sizes="728x90" data-gpt-targeting="pos=LB1;articleid=767;"></div>
        </div>
    </aside>

<div class="u-position-relative">
    <header class="c-header u-mb-24" data-test="publisher-header">
        <div class="c-header__container">
            <div class="c-header__brand">
                
    <a id="logo" class="u-display-block" href="/" title="Go to homepage" data-test="springerlink-logo">
        <picture>
            <source type="image/svg+xml" srcset=/oscar-static/images/springerlink/svg/springerlink-253e23a83d.svg>
            <img src=/oscar-static/images/springerlink/png/springerlink-1db8a5b8b1.png alt="SpringerLink" width="148" height="30" data-test="header-academic">
        </picture>
        
        
    </a>


            </div>
            <div class="c-header__navigation">
                
    
        <button type="button"
                class="c-header__link u-button-reset u-mr-24"
                data-expander
                data-expander-target="#popup-search"
                data-expander-autofocus="firstTabbable"
                data-test="header-search-button">
            <span class="u-display-flex u-align-items-center">
                Search
                <svg class="u-icon u-flex-static u-ml-8" width="22" height="22" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </span>
        </button>
        <nav>
            <ul class="c-header__menu">
                
                <li class="c-header__item">
                    <a
                        data-test="login-link"
                        class="c-header__link"
                        href="//link.springer.com/signup-login?previousUrl=https%3A%2F%2Flink.springer.com%2Farticle%2F10.1007%2Fs10898-019-00767-0"
                        data-track="click"
                        data-track-category="header"
                        data-track-action="login header"
                        data-track-label="link">Log in</a>
                </li>
                

                
            </ul>
        </nav>
    

    



            </div>
        </div>
    </header>

    
        <div id="popup-search" class="c-popup-search u-mb-16 js-header-search u-js-hide">
            <div class="c-popup-search__content">
                <div class="u-container">
                    <div class="c-popup-search__container" data-test="springerlink-popup-search">
                        <div class="app-search">
    <form role="search" method="GET" action="/search" >
        <label for="search" class="app-search__label">Search SpringerLink</label>
        <div class="app-search__content">
            <input id="search" class="app-search__input" data-search-input autocomplete="off" role="textbox" name="query" type="text" value="">
            <button class="app-search__button" type="submit">
                <span class="u-visually-hidden">Search</span>
                <svg class="u-icon" width="14" height="14" aria-hidden="true" focusable="false">
                    <use xlink:href="#global-icon-search"></use>
                </svg>
            </button>
            
                <input type="hidden" name="searchType" value="publisherSearch">
            
            
        </div>
    </form>
</div>

                    </div>
                </div>
            </div>
        </div>
    
</div>

        

    <div class="u-container u-mt-32 u-mb-32 u-clearfix" id="main-content" data-component="article-container">
        <main class="c-article-main-column u-float-left js-main-column" data-track-component="article body">
            
                
                <div class="c-context-bar u-hide" data-component="context-bar" aria-hidden="true">
                    <div class="c-context-bar__container u-container">
                        <div class="c-context-bar__title">
                            When is there a representer theorem?
                        </div>
                        
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10898-019-00767-0.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button" download>
            
                <span>Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>

                    </div>
                </div>
            

            <div class="c-pdf-button__container">
                
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10898-019-00767-0.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button" download>
            
                <span>Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>

            </div>

            <article itemscope itemtype="http://schema.org/ScholarlyArticle" lang="en">
                <div class="c-article-header">
                    <header>
                        <ul class="c-article-identifiers" data-test="article-identifier">
                            
    
    
        <li class="c-article-identifiers__item">
            <span class="c-article-identifiers__open" data-test="open-access">Open Access</span>
        </li>
    
    

                            <li class="c-article-identifiers__item"><a href="#article-info" data-track="click" data-track-action="publication date" data-track-label="link">Published: <time datetime="2019-04-08" itemprop="datePublished">08 April 2019</time></a></li>
                        </ul>

                        
                        <h1 class="c-article-title" data-test="article-title" data-article-title="" itemprop="name headline">When is there a representer theorem?</h1><p lang="en">Nondifferentiable regularisers and Banach spaces</p>
                        <ul class="c-author-list js-etal-collapsed" data-etal="25" data-etal-small="3" data-test="authors-list" data-component-authors-activator="authors-list"><li class="c-author-list__item" itemprop="author" itemscope="itemscope" itemtype="http://schema.org/Person"><span itemprop="name"><a data-test="author-name" data-track="click" data-track-action="open author" data-track-label="link" href="#auth-Kevin-Schlegel" data-author-popup="auth-Kevin-Schlegel" data-corresp-id="c1">Kevin Schlegel<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-email"></use></svg></a></span><span class="u-js-hide"> 
            <a class="js-orcid" itemprop="url" href="http://orcid.org/0000-0002-7660-1051"><span class="u-visually-hidden">ORCID: </span>orcid.org/0000-0002-7660-1051</a></span><sup class="u-js-hide"><a href="#Aff1">1</a><span itemprop="affiliation" itemscope="itemscope" itemtype="http://schema.org/Organization" class="u-visually-hidden"><meta itemprop="name" content="University of Oxford" /><meta itemprop="address" content="0000 0004 1936 8948, grid.4991.5, Mathematical Institute, University of Oxford, Andrew Wiles Building, Radcliffe Observatory Quarter Woodstock Road, Oxford, OX2 6GG, UK" /></span></sup> </li></ul>
                        <p class="c-article-info-details" data-container-section="info">
                            
    <a data-test="journal-link" href="/journal/10898"><i data-test="journal-title">Journal of Global Optimization</i></a>

                            <b data-test="journal-volume"><span class="u-visually-hidden">volume</span> 74</b>, <span class="u-visually-hidden">pages</span><span itemprop="pageStart">401</span>–<span itemprop="pageEnd">415</span>(<span data-test="article-publication-year">2019</span>)<a href="#citeas" class="c-article-info-details__cite-as u-hide-print" data-track="click" data-track-action="cite this article" data-track-label="link">Cite this article</a>
                        </p>
                        
    

                        <div data-test="article-metrics">
                            <div id="altmetric-container">
    <div class="c-article-metrics-bar__wrapper u-clear-both">
        <ul class="c-article-metrics-bar u-list-reset">
            
                <li class=" c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__count">1200 <span class="c-article-metrics-bar__label">Accesses</span></p>
                </li>
            
            
                <li class="c-article-metrics-bar__item">
                    <p class="c-article-metrics-bar__count">2 <span class="c-article-metrics-bar__label">Citations</span></p>
                </li>
            
            
                
                    <li class="c-article-metrics-bar__item">
                        <p class="c-article-metrics-bar__count">1 <span class="c-article-metrics-bar__label">Altmetric</span></p>
                    </li>
                
            
            <li class="c-article-metrics-bar__item">
                <p class="c-article-metrics-bar__details"><a href="/article/10.1007%2Fs10898-019-00767-0/metrics" data-track="click" data-track-action="view metrics" data-track-label="link" rel="nofollow">Metrics <span class="u-visually-hidden">details</span></a></p>
            </li>
        </ul>
    </div>
</div>

                        </div>
                            
    

    

                    </header>
                </div>

                <div data-article-body="true" data-track-component="article body" class="c-article-body">
                    <section aria-labelledby="Abs1" data-title="Abstract" lang="en"><div class="c-article-section" id="Abs1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Abs1">Abstract</h2><div class="c-article-section__content" id="Abs1-content"><p>We consider a general regularised interpolation problem for learning a parameter vector from data. The well known representer theorem says that under certain conditions on the regulariser there exists a solution in the linear span of the data points. This is at the core of kernel methods in machine learning as it makes the problem computationally tractable. Necessary and sufficient conditions for differentiable regularisers on Hilbert spaces to admit a representer theorem have been proved. We extend those results to nondifferentiable regularisers on uniformly convex and uniformly smooth Banach spaces. This gives a (more) complete answer to the question when there is a representer theorem. We then note that for regularised interpolation in fact the solution is determined by the function space alone and independent of the regulariser, making the extension to Banach spaces even more valuable.</p></div></div></section>
                    
    


                    

                    

                    
                        
                            <section aria-labelledby="Sec1" data-title="Introduction"><div class="c-article-section" id="Sec1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec1">Introduction</h2><div class="c-article-section__content" id="Sec1-content"><p>Regularisation is often described as a process of adding additional information or using previous knowledge about the solution to solve an ill-posed problem or to prevent an algorithm from overfitting to the given data. This makes it a very important method for learning a function from empirical data from very large classes of functions. Intuitively its purpose is to pick from all the functions that may explain the data the function which is the simplest in some suitable sense. Hence regularisation appears in various disciplines wherever empirical data is produced and has to be explained by a function. This has motivated to study regularisation problems in mathematics, statistics and computer science and in particular in machine learning theory (Cucker and Smale [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Cucker, F., Smale, S.: On the mathematical foundations of learning. Bull. Am. Math. Soc. 39(1), 1–49 (2001)" href="/article/10.1007/s10898-019-00767-0#ref-CR4" id="ref-link-section-d15187e328">4</a>], Shawe-Taylor and Cristianini [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Shawe-Taylor, J., Cristianini, N.: Kernel Methods for Pattern Analysis. Cambridge University Press, Cambridge (2004). &#xA;                    https://doi.org/10.1017/CBO9780511809682&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10898-019-00767-0#ref-CR16" id="ref-link-section-d15187e331">16</a>], Micchelli and Pontil [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Micchelli, C.A., Pontil, M.: Learning the kernel function via regularization. J. Mach. Lear. Res. 6, 1099–1125 (2005)" href="/article/10.1007/s10898-019-00767-0#ref-CR13" id="ref-link-section-d15187e334">13</a>]).</p><p>In particular regularisation in Hilbert spaces has been studied in the literature for various reasons. First of all the existence of inner products allows for the design of algorithms with very clear geometric intuitions often based on orthogonal projections or the fact that the inner product can be seen as a kind of similarity measure.</p><p>But in fact crucial for the success of regularisation methods in Hilbert spaces is the well known <i>representer theorem</i> which states that for certain regularisers there is always a solution in the linear span of the data points (Kimeldorf and Wahba [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 8" title="Kimeldorf, G., Wahba, G.: Some results on Tchebycheffian spline functions. J. Math. Anal. Appl. 33(1), 82–95 (1971). &#xA;                    https://doi.org/10.1016/0022-247X(71)90184-3&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10898-019-00767-0#ref-CR8" id="ref-link-section-d15187e346">8</a>], Cox and O’Sullivan [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Cox, D.D., O’Sullivan, F.: Asymptotic analysis of penalized likelihood and related estimators. Ann. Stat. 18(4), 1676–1695 (1990). &#xA;                    https://doi.org/10.1214/aos/1176347872&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10898-019-00767-0#ref-CR3" id="ref-link-section-d15187e349">3</a>], Schölkopf and Smola [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Schölkopf, B., Herbrich, R., Smola, A.J.: A generalized representer theorem. In: Helmbold, D., Williamson, B. (eds.) Computational Learning Theory, pp. 416–426. Springer, Berlin (2001)" href="/article/10.1007/s10898-019-00767-0#ref-CR14" id="ref-link-section-d15187e352">14</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="Smola, J.A., Schölkopf, B.: On a kernel-based method for pattern recognition, regression, approximation, and operator inversion. Algorithmica 22(1), 211–231 (1998). &#xA;                    https://doi.org/10.1007/PL00013831&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10898-019-00767-0#ref-CR17" id="ref-link-section-d15187e355">17</a>]). This means that the problem reduces to finding a function in a finite dimensional subspace of the original function space which is often infinite dimensional. It is this dimension reduction that makes the problem computationally tractable.</p><p>Another reason for Hilbert space regularisation finding a variety of applications is the <i>kernel trick</i> which allows for any algorithm which is formulated in terms of inner products to be modified to yield a new algorithm based on a different symmetric, positive semidefinite kernel leading to learning in <i>reproducing kernel Hilbert spaces</i> (Schölkopf and Smola [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Schölkopf, B., Smola, A.J.: Learning with Kernels. MIT Press, Cambridge (2002)" href="/article/10.1007/s10898-019-00767-0#ref-CR15" id="ref-link-section-d15187e367">15</a>], Shawe-Taylor and Cristianini [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Shawe-Taylor, J., Cristianini, N.: Kernel Methods for Pattern Analysis. Cambridge University Press, Cambridge (2004). &#xA;                    https://doi.org/10.1017/CBO9780511809682&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10898-019-00767-0#ref-CR16" id="ref-link-section-d15187e370">16</a>]). This way nonlinearities can be introduced in the otherwise linear setup. Furthermore kernels can be defined on input sets which a priori do not have a mathematical structure by embeddings into a Hilbert space.</p><p>When we are speaking of regularisation we are referring to <i>Tikhonov regularisation</i>, i.e. an optimisation problem of the form</p><div id="Equ9" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \min \left\{ \mathcal {E}({(\left&lt;{f},{x_i}\right&gt;_{\mathcal {H}},y_i)}^m_{i=1}) + \lambda \varOmega (f)\,:\,f\in \mathcal {H}\right\} \end{aligned}$$</span></div></div><p>where <span class="mathjax-tex">\(\mathcal {H}\)</span> is a Hilbert space, <span class="mathjax-tex">\(\left\{ (x_i,y_i) \,:\,i\in \mathbb {N}_m\right\} \subset \mathcal {H}\times Y\)</span> is a set of given input/output data with <span class="mathjax-tex">\(Y\subseteq \mathbb {R}\)</span>, <span class="mathjax-tex">\(\mathcal {E}:\mathbb {R}^m\times Y^m\rightarrow \mathbb {R}\)</span> is an <i>error function</i>, <span class="mathjax-tex">\(\varOmega \,:\mathcal {H}\rightarrow \mathbb {R}\)</span> a <i>regulariser</i> and <span class="mathjax-tex">\(\lambda &gt;0\)</span> is a <i>regularisation parameter</i>. Argyriou et al. [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Argyriou, A., Micchelli, C.A., Pontil, M.: When is there a representer theorem? vector versus matrix regularizers. J. Mach. Learn. Res. 10, 2507–2529 (2009)" href="/article/10.1007/s10898-019-00767-0#ref-CR1" id="ref-link-section-d15187e762">1</a>] show that under very mild conditions this regularisation problem admits a linear representer theorem if and only if the regularised interpolation problem</p><div id="Equ1" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \min \left\{ \varOmega (f)\,:\,f\in \mathcal {H}, \left&lt;{f},{x_i}\right&gt;_{\mathcal {H}}=y_i\,\forall i=1,\ldots ,m\right\} \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (1)
                </div></div><p>admits a linear representer theorem. They argue that we can thus focus on the regularised interpolation problem which is more convenient to study. It is easy to see that their argument holds for the more general setting of the problem which we are going to introduce in this paper so we are going to take the same viewpoint in this paper and consider regularised interpolation.</p><p>We will be interested in regularisation not only in Hilbert spaces as stated above but <i>extend the theory to uniformly convex, uniformly smooth Banach spaces</i>, allowing for learning in a much larger variety of spaces. While any two Hilbert spaces of the same dimension are linearly isometrically isomorphic this is far from true for Banach spaces so they exhibit much richer geometric variety which may be exploited in learning algorithms. Furthermore we may encounter applications where the data has some intrinsic structure so that it cannot be embedded into a Hilbert space. Having a large amount of Banach spaces for potential embeddings may help to overcome this problem. Analogous to learning in reproducing kernel Hilbert spaces the generalisation to Banach spaces allows for learning in <i>reproducing kernel Banach spaces</i> which have been introduced by Zhang et al. [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Zhang, H., Xu, Y., Zhang, J.: reproducing kernel banach spaces for machine learning. J. Mach. Learn. Res. 10, 2741–2775 (2009)" href="/article/10.1007/s10898-019-00767-0#ref-CR18" id="ref-link-section-d15187e892">18</a>]. Our results regarding the existence of representer theorems are in line with Zhang and Zhang’s work on representer theorems for reproducing kernel Banach spaces [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Zhang, H., Zhang, J.: Regularized learning in banach spaces as an optimization problem: representer theorems. J. Global Optim. 54(2), 235–250 (2012). &#xA;                    https://doi.org/10.1007/s10898-010-9575-z&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10898-019-00767-0#ref-CR19" id="ref-link-section-d15187e895">19</a>].</p><p>But as we will show at the end of this paper the variety of spaces to pose the problem in is of even greater importance. It is often said that the regulariser favours solutions with a certain desirable property. We will show that in fact for regularised interpolation when we rely on the linear representer theorem it is essentially <i>the choice of the space</i>, and only the choice of the space not the choice of the regulariser, which <i>determines the solution</i>.</p><p>It is well known that non-decreasing functions of the Hilbert space norm admit a linear representer theorem. Argyriou et al. [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Argyriou, A., Micchelli, C.A., Pontil, M.: When is there a representer theorem? vector versus matrix regularizers. J. Mach. Learn. Res. 10, 2507–2529 (2009)" href="/article/10.1007/s10898-019-00767-0#ref-CR1" id="ref-link-section-d15187e910">1</a>] showed that this condition is not just necessary but for differentiable regularisers also sufficient. In this paper we <i>remove the differentiablity condition</i> and show that any regulariser on a uniformly convex and uniformly smooth Banach space that admits a linear representer theorem is in fact very close to being radially symmetric, thus giving a (more) complete answer to the question when there is a representer theorem. Before presenting those results we present the necessary theory of semi-inner products to generalise the Hilbert space setting considered by Argyriou, Micchelli and Pontil to Banach spaces.</p><p>In Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10898-019-00767-0#Sec3">2</a> we will introduce the notion of <i>semi-inner products</i> as defined by Lumer [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Lumer, G.: Semi-inner-product spaces. Trans. Am. Math. Soc. 100(1), 29–43 (1961)" href="/article/10.1007/s10898-019-00767-0#ref-CR11" id="ref-link-section-d15187e925">11</a>] and later extended by Giles [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 6" title="Giles, J.R.: Classes of semi-inner-product spaces. Trans. Am. Math. Soc. 129(3), 436–446 (1967)" href="/article/10.1007/s10898-019-00767-0#ref-CR6" id="ref-link-section-d15187e928">6</a>]. We will state the results without proofs as they mostly are not difficult and can be found in the original papers. Another extensive reference about semi-inner products and their properties is the work by Dragomir [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Dragomir, S.S.: Semi-inner Products and Applications. Nova Science Publishers, Hauppauge (2004)" href="/article/10.1007/s10898-019-00767-0#ref-CR5" id="ref-link-section-d15187e931">5</a>].</p><p>After introducing the relevant theory we will present the generalised regularised interpolation problem in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10898-019-00767-0#Sec4">3</a>, replacing the inner product in Eq. (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s10898-019-00767-0#Equ1">1</a>) by a semi-inner product. We then state one of the main results of the paper that regularisers that admit a representer theorem are almost radially symmetric in a way that will be made precise in the statement. Before giving the proof of the theorem we state and prove two essential lemmas capturing most of the important structure of the problem to prove the theorem. We finish the section by giving the proof of the main result.</p><p>Finally in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10898-019-00767-0#Sec5">4</a> we prove that in fact for admissible regularisers there is a unique solution of the regularised interpolation problem in the linear span of the data and it is independent of the regulariser. This in particular means that we may choose the regulariser which is most suitable for our task at hand without changing the solution.</p><h3 class="c-article__sub-heading" id="Sec2">Notation</h3><p>Before the main sections we briefly introduce some notation used throughout the paper. We use <span class="mathjax-tex">\(\mathbb {N}_m\)</span> as a shorthand notation for the set <span class="mathjax-tex">\(\{1,\ldots ,m\}\subset \mathbb {N}\)</span>. We will assume we have <i>m</i> data points <span class="mathjax-tex">\(\left\{ (x_i,y_i) \,:\,i\in \mathbb {N}_m\right\} \subset \mathcal {B}\times Y\)</span>, where <span class="mathjax-tex">\(\mathcal {B}\)</span> will always denote a uniformly convex, uniformly smooth real Banach space and <span class="mathjax-tex">\(Y\subseteq \mathbb {R}\)</span>. Typical examples of <i>Y</i> are finite sets of integers for classification problems, e.g. <span class="mathjax-tex">\(\{-1,1\}\)</span> for binary classification, or the whole of <span class="mathjax-tex">\(\mathbb {R}\)</span> for regression.</p><p>We briefly recall the definitions of a Banach space being uniformly convex and uniformly smooth, further details can be found in [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Brezis, H.: Functional Analysis, Sobolev Spaces and Partial Differential Equations. Universitext, 1st edn. Springer, New York (2011)" href="/article/10.1007/s10898-019-00767-0#ref-CR2" id="ref-link-section-d15187e1212">2</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Köthe, G.: Topological Vectorspaces I, Grundlehren der Mathematischen Wissenschaften, vol. 159. Springer, Berlin (1983)" href="/article/10.1007/s10898-019-00767-0#ref-CR9" id="ref-link-section-d15187e1215">9</a>, <a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 10" title="Lindenstrauss, J., Tzafriri, L.: Classical Banach Spaces II: Function Spaces, Ergebnisse der Mathematik und ihrer Grenzgebiete, vol. 97. Springer, Berlin (1979)" href="/article/10.1007/s10898-019-00767-0#ref-CR10" id="ref-link-section-d15187e1218">10</a>].</p>
                  <h3 class="c-article__sub-heading" id="FPar1">Definition 1</h3>
                  <p>(<i>Uniformly convex Banach space</i>) A normed vector space <i>V</i> is said to be uniformly convex if for every <span class="mathjax-tex">\(\varepsilon &gt;0\)</span> there exists a <span class="mathjax-tex">\(\delta &gt;0\)</span> such that if <span class="mathjax-tex">\(x,y\in V\)</span> with <span class="mathjax-tex">\({||}{x}{||}_V={||}{y}{||}_V=1\)</span> and <span class="mathjax-tex">\({||}{x-y}{||}_V &gt; \varepsilon \)</span> then <span class="mathjax-tex">\({||}{\frac{x+y}{2}}{||}_V &lt; 1 - \delta \)</span>.</p>
                
                  <h3 class="c-article__sub-heading" id="FPar2">Definition 2</h3>
                  <p>(<i>Uniformly smooth Banach space</i>) A normed vector space <i>V</i> is said to be uniformly smooth if for every <span class="mathjax-tex">\(\varepsilon &gt;0\)</span> there exists <span class="mathjax-tex">\(\delta &gt;0\)</span> such that if <span class="mathjax-tex">\(x,y\in V\)</span> with <span class="mathjax-tex">\({||}{x}{||}_V=1, {||}{y}{||}_V\le \delta \)</span> then <span class="mathjax-tex">\({||}{x+y}{||}_V+{||}{x-y}{||}_V\le 2+\varepsilon {||}{y}{||}_V\)</span>.</p>
                
                  <h3 class="c-article__sub-heading" id="FPar3">Remark 1</h3>
                  <p>There are two equivalent conditions of uniform smoothness which we will make use of in this paper.</p><ol class="u-list-style-none">
                      <li>
                        <span class="u-custom-list-number">(i)</span>
                        
                          <p>The modulus of smoothness of the space <i>V</i> is defined as </p><div id="Equ2" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \rho _V(\delta ) = \sup \left\{ \frac{{||}{x+y}{||}_V+{||}{x-y}{||}_V}{2} - 1 \,:\,{||}{x}{||}_V=1, {||}{y}{||}_V=\delta \right\} \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (2)
                </div></div><p> Now <i>V</i> is uniformly smooth if and only if <span class="mathjax-tex">\(\frac{\rho _V(\delta )}{\delta }\underset{{\delta }\rightarrow {0}}{\longrightarrow }0\)</span>.</p>
                        
                      </li>
                      <li>
                        <span class="u-custom-list-number">(ii)</span>
                        
                          <p>The norm on <i>V</i> is said to be uniformly Fréchet differentiable if the limit </p><div id="Equ10" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \lim \limits _{t\rightarrow 0}\frac{{||}{x+t\cdot y}{||}_V-{||}{x}{||}_V}{t} \end{aligned}$$</span></div></div><p> exists uniformly for all real <i>t</i> and <span class="mathjax-tex">\(x,y\in V\)</span> with <span class="mathjax-tex">\({||}{x}{||}_V={||}{y}{||}_V= 1\)</span>. The space <i>V</i> is uniformly smooth if its norm is uniformly Fréchet differentiable.</p>
                        
                      </li>
                    </ol>
                <p>We always write <span class="mathjax-tex">\(\mathcal {H}\)</span> to denote a Hilbert space and for the first part of Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10898-019-00767-0#Sec3">2</a> we will be speaking of general normed linear spaces denoted by <i>V</i>. Once we have seen the reasons to require the space to be a uniformly convex and uniformly smooth Banach space the remainder of Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10898-019-00767-0#Sec3">2</a> and the paper will consider such spaces denoted by <span class="mathjax-tex">\(\mathcal {B}\)</span>. When only the norm <span class="mathjax-tex">\({||}{\cdot }{||}_\mathcal {B}\)</span> on <span class="mathjax-tex">\(\mathcal {B}\)</span> is considered the subscript will often be omitted for simplicity. Throughout we will denote the inner product on a Hilbert space by <span class="mathjax-tex">\(\left&lt;{\cdot },{\cdot }\right&gt;_{\mathcal {H}}\)</span> and a semi-inner product on a normed linear space by <span class="mathjax-tex">\(\left[ {\cdot },{\cdot }\right] _{V}\)</span>.</p></div></div></section><section aria-labelledby="Sec3" data-title="Semi-inner product spaces"><div class="c-article-section" id="Sec3-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec3">Semi-inner product spaces</h2><div class="c-article-section__content" id="Sec3-content"><p>There are various definitions of semi-inner products aiming to generalise Hilbert space methods to more general cases. The notion of semi-inner products we are going to use was first introduced by Lumer [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Lumer, G.: Semi-inner-product spaces. Trans. Am. Math. Soc. 100(1), 29–43 (1961)" href="/article/10.1007/s10898-019-00767-0#ref-CR11" id="ref-link-section-d15187e2554">11</a>] and further developed by Giles [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 6" title="Giles, J.R.: Classes of semi-inner-product spaces. Trans. Am. Math. Soc. 129(3), 436–446 (1967)" href="/article/10.1007/s10898-019-00767-0#ref-CR6" id="ref-link-section-d15187e2557">6</a>]. In comparison to inner products the assumption of symmetry, or equivalently additivity in the second argument, is dropped. Following Giles we assume homogeneity in the second argument. Moreover we need to assume that the Cauchy–Schwarz inequality holds, as it is crucial for the semi-inner products to have inner-product like behaviour.</p><p>In this section we will give a brief summary of the most important results. More details can be found in the two papers referenced above. Moreover an extensive overview of the theory of this and other notions of semi-inner products can be found in Dragomir [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Dragomir, S.S.: Semi-inner Products and Applications. Nova Science Publishers, Hauppauge (2004)" href="/article/10.1007/s10898-019-00767-0#ref-CR5" id="ref-link-section-d15187e2563">5</a>]. While all results in this section can be given for complex vector spaces we will only present them for the real case as our results only apply to real vector spaces.</p>
                <h3 class="c-article__sub-heading" id="FPar4">Definition 3</h3>
                <p>(<i>Semi-inner product</i>) A semi-inner product (s.i.p.) on a real vector space <i>V</i> is a map <span class="mathjax-tex">\(\left[ {\cdot },{\cdot }\right] _{V}:V\times V\rightarrow \mathbb {R}\)</span> which is linear in the first argument, homogeneous in the second argument, positive definite, and satisfies the Cauchy–Schwarz inequality.</p>
              <p>With these properties a semi-inner product <span class="mathjax-tex">\(\left[ {\cdot },{\cdot }\right] _{V}\)</span> induces a norm <span class="mathjax-tex">\(\left[ {x},{x}\right] _{V}={||}{x}{||}_V\)</span> on <i>V</i>. Conversely every norm <span class="mathjax-tex">\({||}{\cdot }{||}_V\)</span> on a linear space <i>V</i> is induced by at least one semi-inner product, i.e. there exists at least one semi-inner product <span class="mathjax-tex">\(\left[ {\cdot },{\cdot }\right] _{V}\)</span> such that <span class="mathjax-tex">\({||}{x}{||}_V=\left[ {x},{x}\right] _{V}\)</span>. This means that every normed linear space is a s.i.p. space, but the semi-inner product inducing the norm is in general not unique. We do have uniqueness for uniformly smooth spaces though.</p>
                <h3 class="c-article__sub-heading" id="FPar5">Proposition 1</h3>
                <p>If the norm <span class="mathjax-tex">\({||}{\cdot }{||}_V\)</span> on <i>V</i> is uniformly Fréchet differentiable as defined in Remark <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10898-019-00767-0#FPar3">1</a>, then the differential of the norm for <span class="mathjax-tex">\(x\ne 0\)</span> is given by</p><div id="Equ11" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \lim \limits _{t\rightarrow 0} \frac{{||}{x+ty}{||}_V - {||}{x}{||}_V}{t} = \frac{{\text {Re}}\left[ {y},{x}\right] _{V}}{{||}{x}{||}_V} \end{aligned}$$</span></div></div>
              <p>The existence of a semi-inner product allows us to define a notion of orthogonality analogous to orthogonality in Hilbert spaces by requiring the semi-inner product to be zero. It turns out that this is equivalent to a generalisation of orthogonality to normed linear spaces introduced by James [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="James, R.C.: Orthogonality and linear functionals in normed linear spaces. Trans. Am. Math. Soc. 61(2), 265–292 (1947)" href="/article/10.1007/s10898-019-00767-0#ref-CR7" id="ref-link-section-d15187e3126">7</a>]. James in particular points out that his definition is closely related to linear functionals and hyperplanes. This is essential for our applications as we will see in the main part of the paper.</p><p>The lack of symmetry of the semi-inner product means that our notion of orthogonality is not symmetric in general and <i>x</i> being normal to <i>y</i> does not imply that <i>y</i> is normal to <i>x</i>.</p>
                <h3 class="c-article__sub-heading" id="FPar6">Definition 4</h3>
                <p>(<i>Orthogonality</i>) Let <i>V</i> be a s.i.p. space. For <span class="mathjax-tex">\(x,y\in V\)</span> we say <i>x</i> is normal to <i>y</i> if <span class="mathjax-tex">\(\left[ {y},{x}\right] _{V}=0\)</span>.</p>
                <p>This is equivalent to James orthogonality, namely for <span class="mathjax-tex">\(x,y\in V\)</span></p><div id="Equ12" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \left[ {y},{x}\right] _{V} = 0 \Leftrightarrow {||}{x+\lambda y}{||}_V \ge {||}{x}{||}_V \quad \text{ for } \text{ all } \lambda \in \mathbb {R}\end{aligned}$$</span></div></div><p>A vector <span class="mathjax-tex">\(x\in V\)</span> is normal to a subspace <span class="mathjax-tex">\(U\subset V\)</span> if <i>x</i> is normal to all <span class="mathjax-tex">\(y\in U\)</span>. Thus the orthogonal complement of <i>U</i> is defined as</p><div id="Equ13" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} U^\perp = \left\{ x_\perp \in V \,:\,\left[ {x},{x_\perp }\right] _{V}=0\,\forall x\in U\right\} \end{aligned}$$</span></div></div>
              <p>The relation to James orthogonality also helps to get a geometric understanding of what orthogonality means in a s.i.p. space. From Definition <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10898-019-00767-0#FPar6">4</a> it is immediately clear that <i>x</i> being normal to <i>y</i> means that the vector <i>y</i> is tangent to the ball <span class="mathjax-tex">\(B(0, {||}{x}{||})\)</span> at the point <i>x</i>, where <span class="mathjax-tex">\(B(0,{||}{x}{||})\)</span> is the ball of radius <span class="mathjax-tex">\({||}{x}{||}\)</span> centred at the origin.</p><p>If the space is a uniformly convex Banach space there exists a unique orthogonal decomposition for every <span class="mathjax-tex">\(x\in V\)</span>. This is because in a uniformly convex space there is a unique closest point in a closed linear subspace and one easily checks that this immediately leads to a unique orthogonal decomposition.</p><p>For uniformly convex, uniformly smooth Banach spaces we are also able to establish a Riesz representation theorem using the semi-inner product.</p>
                <h3 class="c-article__sub-heading" id="FPar7">Theorem 1</h3>
                <p>(<i>Riesz representation theorem</i>) Let <i>V</i> be a uniformly convex, uniformly smooth s.i.p. space. Then for every <span class="mathjax-tex">\(f\in V^*\)</span> there exists a unique vector <span class="mathjax-tex">\(y\in V\)</span> such that <span class="mathjax-tex">\(f(x)=\left[ {x},{y}\right] _{V}\)</span> for all <span class="mathjax-tex">\(x\in V\)</span> and <span class="mathjax-tex">\({||}{y}{||}_V = {||}{f}{||}_{V^*}\)</span>.</p>
              <p>Summarising the above results we see that a necessary structure to have a unique semi-inner product inducing the norm and allowing for a Riesz representation theorem is that the space is a uniformly convex and uniformly Fréchet differentiable Banach space. For simplicity we will be calling such spaces uniform.</p>
                <h3 class="c-article__sub-heading" id="FPar8">Definition 5</h3>
                <p>(<i>Uniform Banach space</i>) We say a space <i>V</i> is uniform if it is a uniformly convex and uniformly Fréchet differentiable Banach space.</p>
              <p>It is well known that the dual space of a uniform Banach space is itself uniform. Lastly we note that the duality mapping of a uniform Banach space is norm-to-norm continuous.The proof for this is standard and can be found in the appendix.</p>
                <h3 class="c-article__sub-heading" id="FPar9">Proposition 2</h3>
                <p>The duality map <span class="mathjax-tex">\(*:\mathcal {B}\rightarrow \mathcal {B}^*, x\mapsto x^*\)</span> is norm-to-norm continuous. In particular <span class="mathjax-tex">\(\left[ {z},{x+ty}\right] _{\mathcal {B}} \rightarrow \left[ {z},{x}\right] _{\mathcal {B}}\)</span> for all <span class="mathjax-tex">\(x,y,z\in \mathcal {B}\)</span> and <span class="mathjax-tex">\(t\in \mathbb {R}\)</span>.</p>
              <p>Thus the dual map is a homeomorphism from <span class="mathjax-tex">\(\mathcal {B}\)</span> to <span class="mathjax-tex">\(\mathcal {B}^*\)</span> with the norm topologies. It is linear if and only if <span class="mathjax-tex">\(\mathcal {B}\)</span> is a Hilbert space.</p></div></div></section><section aria-labelledby="Sec4" data-title="Existence of representer theorems"><div class="c-article-section" id="Sec4-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec4">Existence of representer theorems</h2><div class="c-article-section__content" id="Sec4-content"><p>The definitions and results of the previous section allow us to consider the regularised interpolation problem</p><div id="Equ3" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \min \left\{ \varOmega (f)\,:\,f\in \mathcal {B},\left[ {f},{x_i}\right] _{\mathcal {B}} = y_i\,\forall i \in \mathbb {N}_m\right\} \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (3)
                </div></div><p>where the domain <span class="mathjax-tex">\(\mathcal {B}\)</span> of the interpolation problem is a real uniform Banach space. This generalises the setting considered by Argyriou et al. in [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Argyriou, A., Micchelli, C.A., Pontil, M.: When is there a representer theorem? vector versus matrix regularizers. J. Mach. Learn. Res. 10, 2507–2529 (2009)" href="/article/10.1007/s10898-019-00767-0#ref-CR1" id="ref-link-section-d15187e4431">1</a>] where the case of a Hilbert space domain is considered. In that setting the linear representer theorem states that there exists a solution to the interpolation problem which is in the linear span of the data points. Our work, similarly as [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Micchelli, C.A., Pontil, M.: A function representation for learning in banach spaces. In: Shawe-Taylor, J., Singer, Y. (eds.) Learning Theory, pp. 255–269. Springer, Berlin (2004)" href="/article/10.1007/s10898-019-00767-0#ref-CR12" id="ref-link-section-d15187e4434">12</a>], hints that in its essence the representer theorem is a result about the dual space rather than the space itself. Since in a Hilbert space the dual element is the element itself this doesn’t become apparent in this setting and we obtain a result in the space itself. As the duality map is nonlinear for any Banach space which is not Hilbert we need to adjust the formulation of the representer theorem. Namely the linear representer theorem in a uniform Banach space states that there exists a solution such that its dual element is in the linear span of the dual elements of the data points. This is made precise in the following definition which is the analogue of Argyriou, Micchelli and Pontil calling regularisers which always admit a linear representer theorem admissible.</p>
                <h3 class="c-article__sub-heading" id="FPar10">Definition 6</h3>
                <p>(<i>Admissible regulariser</i>) We say a function <span class="mathjax-tex">\(\varOmega :\mathcal {B}\rightarrow \mathbb {R}\)</span> is admissible if for any <span class="mathjax-tex">\(m\in \mathbb {N}\)</span> and any given data <span class="mathjax-tex">\(\left\{ (x_i,y_i) \,:\,i\in \mathbb {N}_m\right\} \subset \mathcal {B}\times Y\)</span> such that the interpolation constraints can be satisfied the regularised interpolation problem Eq. (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s10898-019-00767-0#Equ3">3</a>) admits a solution <span class="mathjax-tex">\(f_0\)</span> such that its dual element is of the form</p><div id="Equ14" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} f^*_0=\sum \limits _{i=1}^{m} c_{i}x^*_i \end{aligned}$$</span></div></div>
              <p>With this definition at hand it is now our goal to classify all admissible regularisers. It is well known that being a non-decreasing function of the norm on a Hilbert space is a sufficient condition for the regulariser to be admissible. By a Hahn–Banach argument similar as e.g. in Zhang and Zhang [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Zhang, H., Zhang, J.: Regularized learning in banach spaces as an optimization problem: representer theorems. J. Global Optim. 54(2), 235–250 (2012). &#xA;                    https://doi.org/10.1007/s10898-010-9575-z&#xA;                    &#xA;                  &#xA;                        " href="/article/10.1007/s10898-019-00767-0#ref-CR19" id="ref-link-section-d15187e4690">19</a>] this generalises to our case of uniform Banach spaces. Below we show that this condition is already almost necessary in the sense that admissible regularisers cannot be very far from being radially symmetric.</p>
                <h3 class="c-article__sub-heading" id="FPar11">Theorem 2</h3>
                <p>A function <span class="mathjax-tex">\(\varOmega \)</span> is admissible if and only if it is of the form</p><div id="Equ15" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \varOmega (f) = h(\left[ {f},{f}\right] _{\mathcal {B}}) \end{aligned}$$</span></div></div><p>for some non-decreasing <i>h</i> whenever <span class="mathjax-tex">\({||}{f}{||} \ne r\)</span> for <span class="mathjax-tex">\(r\in \mathcal {R}\)</span>. Here <span class="mathjax-tex">\(\mathcal {R}\)</span> is an at most countable set of radii where <i>h</i> has a jump discontinuity. For any <i>f</i> with <span class="mathjax-tex">\({||}{f}{||}=r\in \mathcal {R}\)</span> the value <span class="mathjax-tex">\(\varOmega (f)\)</span> is only constrained by the monotonicity property, i.e. it has to lie in between <span class="mathjax-tex">\(\lim \limits _{t\nearrow r}h(t)\)</span> and <span class="mathjax-tex">\(\lim \limits _{t\searrow r}h(t)\)</span>.</p>
                <p>In other words, <span class="mathjax-tex">\(\varOmega \)</span> is radially non-decreasing and radially symmetric except for at most countably many circular jump discontinuities. In those discontinuities the function value is only limited by its monotonicity property.</p>
              <p>In [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Argyriou, A., Micchelli, C.A., Pontil, M.: When is there a representer theorem? vector versus matrix regularizers. J. Mach. Learn. Res. 10, 2507–2529 (2009)" href="/article/10.1007/s10898-019-00767-0#ref-CR1" id="ref-link-section-d15187e5097">1</a>] Argyriou et al. show that any admissible regulariser on a Hilbert space is non-decreasing in orthogonal directions. An analogous result is true for uniform Banach spaces but with orthogonality not being symmetric and our intuition gained from the equivalence with James orthogonality we see that in fact it is tangential directions in which the regulariser is non-decreasing. This also becomes clear from the proofs in [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Argyriou, A., Micchelli, C.A., Pontil, M.: When is there a representer theorem? vector versus matrix regularizers. J. Mach. Learn. Res. 10, 2507–2529 (2009)" href="/article/10.1007/s10898-019-00767-0#ref-CR1" id="ref-link-section-d15187e5100">1</a>], in particular when proving radial symmetry.</p><p>Before we can prove the analogous result for uniform Banach spaces we need to show that we can extend this tangential bound considerably and a function that is non-decreasing in tangential directions is in fact non-decreasing in norm as is made precise in the following Lemma <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10898-019-00767-0#FPar12">1</a>.</p>
                <h3 class="c-article__sub-heading" id="FPar12">Lemma 1</h3>
                <p>If <span class="mathjax-tex">\(\varOmega (f)\le \varOmega (f+f_T)\)</span> for all <span class="mathjax-tex">\(f,f_T\in \mathcal {B}\)</span> such that <span class="mathjax-tex">\(\left[ {f_T},{f}\right] _{\mathcal {B}}=0\)</span> then for any fixed <span class="mathjax-tex">\(\hat{f}\)</span> we have that <span class="mathjax-tex">\(\varOmega (\hat{f})\le \varOmega (f)\)</span> for all <i>f</i> such that <span class="mathjax-tex">\({||}{\hat{f}}{||}&lt;{||}{f}{||}\)</span>.</p>
              
                <h3 class="c-article__sub-heading" id="FPar13">Proof</h3>
                <p><i>Part 1: (Bound</i><span class="mathjax-tex">\(\varOmega \)</span><i>on the half space given by the tangent through</i><span class="mathjax-tex">\(\hat{f}\)</span>)</p>
                <p>We start by showing that <span class="mathjax-tex">\(\varOmega \)</span> is radially non-decreasing. Since it is non-decreasing along tangential directions this immediately gives the claimed bound for the entire half space given by the tangent through <span class="mathjax-tex">\(\hat{f}\)</span>. The idea of the proof is to move out along a tangent until we can move back along another tangent to hit a given point along the ray <span class="mathjax-tex">\(\lambda \cdot \hat{f}\)</span> as shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10898-019-00767-0#Fig1">1</a>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-1" data-title="Fig. 1"><figure><figcaption><b id="Fig1" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 1</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10898-019-00767-0/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10898-019-00767-0/MediaObjects/10898_2019_767_Fig1_HTML.png?as=webp"></source><img aria-describedby="figure-1-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10898-019-00767-0/MediaObjects/10898_2019_767_Fig1_HTML.png" alt="figure1" loading="lazy" width="685" height="385" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-1-desc"><p>We can extend the tangential bound to the ray <span class="mathjax-tex">\(\lambda \cdot f_0\)</span> by finding the point <span class="mathjax-tex">\(f_t\)</span> along the tangent from where the tangent to <span class="mathjax-tex">\(f_t\)</span> hits the desired point on the ray. Via the tangents to points along the ray the bound then extends to the shaded half space</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10898-019-00767-0/figures/1" data-track-dest="link:Figure1 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                <p>Fix some <span class="mathjax-tex">\(\hat{f}\in \mathcal {B}\)</span> and <span class="mathjax-tex">\(1&lt;\lambda \in \mathbb {R}\)</span> and set <span class="mathjax-tex">\(f=\lambda \cdot \hat{f}\)</span>. We need to show that <span class="mathjax-tex">\(\varOmega (f)\ge \varOmega (\hat{f})\)</span>. Let <span class="mathjax-tex">\(f_T\in \mathcal {B}\)</span> be such that <span class="mathjax-tex">\(\left[ {f_T},{\hat{f}}\right] _{\mathcal {B}}=0\)</span> or equivalently <span class="mathjax-tex">\({||}{\hat{f}+t\cdot f_T}{||}&gt;{||}{\hat{f}}{||}\)</span> for all <span class="mathjax-tex">\(t\ne 0\)</span>. Now let</p><div id="Equ16" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} f_t= &amp; {} \hat{f}+t\cdot f_T\\ g_t= &amp; {} f-f_t=(\lambda -1)\cdot \hat{f}-t\cdot f_T \end{aligned}$$</span></div></div><p>so that <span class="mathjax-tex">\(f_t+g_t=f\)</span>. Note that by strict convexity and continuity of the norm <span class="mathjax-tex">\({||}{f_t}{||}={||}{\hat{f}+t\cdot f_T}{||}\)</span> is continuous and strictly increasing in <i>t</i>.</p>
                <p>Now since <span class="mathjax-tex">\(t\cdot f_T\)</span> is the tangent through <span class="mathjax-tex">\(\hat{f}\)</span> and <span class="mathjax-tex">\(g_t\)</span> points from <span class="mathjax-tex">\(f_t\)</span> to <i>f</i>, for small <i>t</i> for which <span class="mathjax-tex">\({||}{f_t}{||}&lt;{||}{f}{||}\)</span> we must have that</p><div id="Equ4" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} {||}{f_t+s\cdot g_t}{||}&gt;{||}{f_t}{||} \text{ for } \text{ all } s\in (0,1) \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (4)
                </div></div><p>On the other hand for <i>t</i> big enough so that <span class="mathjax-tex">\({||}{f_t}{||}&gt;{||}{f}{||}\)</span> we thus must have</p><div id="Equ5" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} {||}{f_t+s\cdot g_t}{||}&lt;{||}{f_t}{||} \text{ for } s \text{ small } \text{ enough } \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (5)
                </div></div><p>But we know that</p><div id="Equ17" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \lim \limits _{s\rightarrow 0}\frac{{||}{f_t+s\cdot g_t}{||}-{||}{f_t}{||}}{s}=\frac{\left[ {g_t},{f_t}\right] _{\mathcal {B}}}{{||}{f_t}{||}}=\frac{f^*_t(g_t)}{{||}{f_t}{||}} \end{aligned}$$</span></div></div><p>and since the dual map is norm-to-norm continuous <span class="mathjax-tex">\(\frac{f^*_t(g_t)}{{||}{f_t}{||}}\)</span> is clearly continuous in <i>t</i>. By above discussion the expression is positive for small <i>t</i> and negative for large <i>t</i> so by the intermediate value theorem there exists <span class="mathjax-tex">\(t_0\)</span> such that</p><div id="Equ18" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \frac{f^*_{t_0}(g_{t_0})}{{||}{f_{t_0}}{||}} = \frac{\left[ {g_{t_0}},{f_{t_0}}\right] _{\mathcal {B}}}{{||}{f_{t_0}}{||}}= 0 \end{aligned}$$</span></div></div><p>so that indeed <span class="mathjax-tex">\(\left[ {g_{t_0}},{f_{t_0}}\right] _{\mathcal {B}} = 0\)</span> and thus <span class="mathjax-tex">\(g_{t_0}\)</span> is tangential to <span class="mathjax-tex">\(f_{t_0}\)</span>. But this means that <span class="mathjax-tex">\(\varOmega (f)\ge \varOmega (f_{t_0})\ge \varOmega (\hat{f})\)</span> as claimed.</p>
                <p>Hence we have the bound along the entire ray <span class="mathjax-tex">\(\lambda \cdot \hat{f}\)</span> for <span class="mathjax-tex">\(1&lt;\lambda \in \mathbb {R}\)</span> which extends along all tangents through those points to the half space given by the tangent through <span class="mathjax-tex">\(\hat{f}\)</span>, i.e. the shaded region in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10898-019-00767-0#Fig1">1</a>.</p>
                <p>
                  <i>Part 2: (Extend the bound around the circle)</i>
                </p>
                <p>Next we note that we can actually extend the bound further to apply all the way around the circle, namely <span class="mathjax-tex">\(\varOmega (f)\ge \varOmega (\hat{f})\)</span> for all <i>f</i> such that <span class="mathjax-tex">\({||}{f}{||}&gt;{||}{\hat{f}}{||}\)</span>. This is done by considering <span class="mathjax-tex">\(f_t=\hat{f}+t\cdot f_T\)</span> as before but then instead of following the tangent into the half space just considered we follow the tangent in the opposite direction around the circle, as shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10898-019-00767-0#Fig2">2</a>. We fix another point along that tangent and repeat the process, moving around the circle. We claim that by making the step size along each tangent small enough we can this way move around the circle while staying arbitrarily close to it.</p>
                <p>More precisely we need to show that the distance a step along a tangent takes us away from the circle decreases faster than the step along the tangent so that we move considerably further around the circle than away from it with each step, as shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10898-019-00767-0#Fig3">3</a>.</p><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-2" data-title="Fig. 2"><figure><figcaption><b id="Fig2" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 2</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10898-019-00767-0/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10898-019-00767-0/MediaObjects/10898_2019_767_Fig2_HTML.png?as=webp"></source><img aria-describedby="figure-2-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10898-019-00767-0/MediaObjects/10898_2019_767_Fig2_HTML.png" alt="figure2" loading="lazy" width="685" height="385" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-2-desc"><p>By repeatedly taking steps along tangents we can move all the way around the circle</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10898-019-00767-0/figures/2" data-track-dest="link:Figure2 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div><div class="c-article-section__figure js-c-reading-companion-figures-item" data-test="figure" data-container-section="figure" id="figure-3" data-title="Fig. 3"><figure><figcaption><b id="Fig3" class="c-article-section__figure-caption" data-test="figure-caption-text">Fig. 3</b></figcaption><div class="c-article-section__figure-content"><div class="c-article-section__figure-item"><a class="c-article-section__figure-link" data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="/article/10.1007/s10898-019-00767-0/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10898-019-00767-0/MediaObjects/10898_2019_767_Fig3_HTML.png?as=webp"></source><img aria-describedby="figure-3-desc" src="//media.springernature.com/lw685/springer-static/image/art%3A10.1007%2Fs10898-019-00767-0/MediaObjects/10898_2019_767_Fig3_HTML.png" alt="figure3" loading="lazy" width="685" height="385" /></picture></a></div><div class="c-article-section__figure-description" data-test="bottom-caption" id="figure-3-desc"><p>When decreasing the step size along a tangent the step size away from the circle decreases significantly faster so that by making the steps along tangents small enough we can reach any point arbitrarily close to the circle</p></div></div><div class="u-text-right u-hide-print"><a class="c-article__pill-button" data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="/article/10.1007/s10898-019-00767-0/figures/3" data-track-dest="link:Figure3 Full size image" rel="nofollow"><span>Full size image</span><svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-chevron-right"></use></svg></a></div></figure></div>
                <p>As stated in Eq. (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s10898-019-00767-0#Equ2">2</a>) let</p><div id="Equ19" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \rho _\mathcal {B}(\delta ) = \sup \left\{ \frac{{||}{f+g}{||}+{||}{f-g}{||}}{2}-1 \,:\,{||}{f}{||}=1, {||}{g}{||}=\delta \right\} \end{aligned}$$</span></div></div><p>be the modulus of smoothness of the space <span class="mathjax-tex">\(\mathcal {B}\)</span>. For <span class="mathjax-tex">\(f,f_T\in \mathcal {B}\)</span> such that <span class="mathjax-tex">\(\left[ {f_T},{f}\right] _{\mathcal {B}}=0\)</span>, <span class="mathjax-tex">\({||}{f}{||}=1\)</span>, <span class="mathjax-tex">\({||}{f_T}{||}=\delta \)</span> we have that <span class="mathjax-tex">\({||}{f+t\cdot f_T}{||}&gt;{||}{f}{||}\)</span> for all <span class="mathjax-tex">\(t\ne 0\)</span> so in particular <span class="mathjax-tex">\({||}{f-f_T}{||}&gt;{||}{f}{||}\)</span>. We thus easily see that</p><div id="Equ20" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} {||}{f+f_T}{||}&amp;\le 2 + 2\rho _\mathcal {B}(\delta ) - {||}{f-f_T}{||}\\&amp;&lt; 2 + 2\rho _\mathcal {B}(\delta ) - {||}{f}{||}\\&amp;= 1 + 2\rho _\mathcal {B}(\delta ) \end{aligned}$$</span></div></div><p>This means that for a step of order <span class="mathjax-tex">\(\delta \)</span> along a tangent, i.e. <span class="mathjax-tex">\(f_T\)</span> of length <span class="mathjax-tex">\(\delta \)</span>, we take a step of order <span class="mathjax-tex">\(\rho _\mathcal {B}(\delta )\)</span> away from the circle. But since <span class="mathjax-tex">\(\mathcal {B}\)</span> is uniformly smooth we have that <span class="mathjax-tex">\(\frac{\rho _\mathcal {B}(\delta )}{\delta }\rightarrow 0\)</span> as <span class="mathjax-tex">\(\delta \rightarrow 0\)</span> proving that for small enough <span class="mathjax-tex">\(\delta \)</span> indeed the step away from the circle is significantly smaller than the step along the tangent as shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="/article/10.1007/s10898-019-00767-0#Fig3">3</a>.</p>
                <p>Combining both arguments this proves that we can reach any point with norm greater than <span class="mathjax-tex">\({||}{\hat{f}}{||}\)</span> from <span class="mathjax-tex">\(\hat{f}\)</span> only by moving along tangents giving the claimed bound. <span class="mathjax-tex">\(\square \)</span></p>
              <p>Having proved this lemma we are now in the position to prove that indeed any admissible regulariser on a uniform Banach space is non-decreasing in tangential directions. Note that the previous lemma will also play a crucial role in removing the differentiability assumption when establishing the closed form representation of the regulariser in Theorem <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10898-019-00767-0#FPar11">2</a>.</p>
                <h3 class="c-article__sub-heading" id="FPar14">Lemma 2</h3>
                <p>A function <span class="mathjax-tex">\(\varOmega \)</span> is admissible if and only if for every <span class="mathjax-tex">\(f,f_T\in \mathcal {B}\)</span> such that <span class="mathjax-tex">\(\left[ {f_T},{f}\right] _{\mathcal {B}}=0\)</span> we have</p><div id="Equ21" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \varOmega (f)\le \varOmega (f + f_T) \end{aligned}$$</span></div></div><p>if and only if for any fixed <span class="mathjax-tex">\(\hat{f}\)</span> and all <i>f</i> such that <span class="mathjax-tex">\({||}{\hat{f}}{||} &lt; {||}{f}{||}\)</span> we have</p><div id="Equ22" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \varOmega (\hat{f})\le \varOmega (f) \end{aligned}$$</span></div></div>
              
                <h3 class="c-article__sub-heading" id="FPar15">Proof</h3>
                <p><i>Part 1:</i> (<span class="mathjax-tex">\(\varOmega \)</span><i>admissible </i><span class="mathjax-tex">\(\Rightarrow \)</span><i>nondecreasing along tangential directions)</i></p>
                <p>Fix any <span class="mathjax-tex">\(f\in \mathcal {B}\)</span> and consider the regularised interpolation problem</p><div id="Equ23" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \min \left\{ \varOmega (g)\,:\,g\in \mathcal {B},\left[ {f},{g}\right] _{\mathcal {B}} = \left[ {f},{f}\right] _{\mathcal {B}}\right\} \end{aligned}$$</span></div></div><p>As <span class="mathjax-tex">\(\varOmega \)</span> is assumed to be admissible there exists a solution with dual element in <span class="mathjax-tex">\({{\,\mathrm{span}\,}}\{f^*\}\)</span> which by homogeneity of the dual map clearly is <i>f</i> itself. But if <span class="mathjax-tex">\(f_T\)</span> is such that <span class="mathjax-tex">\(\left[ {f_T},{f}\right] _{\mathcal {B}}=0\)</span> then <span class="mathjax-tex">\(\left[ {f+f_T},{f}\right] _{\mathcal {B}}=\left[ {f},{f}\right] _{\mathcal {B}}\)</span> so <span class="mathjax-tex">\(f+f_T\)</span> also satisfies the constraints and hence necessarily <span class="mathjax-tex">\(\varOmega (f+f_T)\ge \varOmega (f)\)</span> as claimed. The second claim follows immediately from Lemma <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10898-019-00767-0#FPar12">1</a>.</p>
                <p>
                  <i>Part 2: (Nondecreasing along tangential directions</i>
                  <span class="mathjax-tex">\(\Rightarrow \)</span>
                  <span class="mathjax-tex">\(\varOmega \)</span>
                  <i>admissible)</i>
                </p>
                <p>Conversely fix any data <span class="mathjax-tex">\(\left\{ (x_i,y_i)\,:\,i\in \mathbb {N}_m\right\} \subset \mathcal {B}\times Y\)</span> such that the interpolation constraints can be satisfied. Let <span class="mathjax-tex">\(f_0\)</span> be a solution to the regularised interpolation problem. If <span class="mathjax-tex">\(f_0^*\in {{\,\mathrm{span}\,}}\{x_i^*\}\)</span> we are done so assume it is not. We let</p><div id="Equ24" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} X^*={{\,\mathrm{span}\,}}\{x_i^*\}\subset \mathcal {B}^*\qquad X=\{x\in \mathcal {B}\,:\,x^*\in X^*\} \end{aligned}$$</span></div></div><p>Further denote by <span class="mathjax-tex">\(Z\subset \mathcal {B}\)</span> the space corresponding to the orthogonal complement of <span class="mathjax-tex">\(X^*\)</span> i.e.</p><div id="Equ25" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} Z = \{f_T\in \mathcal {B}\,:\,f^*_T\in {(X^*)}^\perp \} = \{f_T\in \mathcal {B}\,:\,\left[ {f_T},{x_i}\right] _{\mathcal {B}}=0\,\forall i\in \mathbb {N}_m\} \end{aligned}$$</span></div></div><p>Thus <span class="mathjax-tex">\(Z^*\cap X^*= \{0\}\)</span> and by assumption <span class="mathjax-tex">\(f_0^*\not \in X^*\)</span> and so also <span class="mathjax-tex">\({{\,\mathrm{span}\,}}\{f_0^*\}\cap X^*= \{0\}\)</span>.</p>
                <p>Now by definition we have that</p><div id="Equ26" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} Z=\bigcap _{i\in \mathbb {N}_m}\ker (x_i^*) \end{aligned}$$</span></div></div><p>so the codimension of <i>Z</i> is <i>m</i>. Without loss of generality we can assume that not all <span class="mathjax-tex">\(y_i\)</span> are zero as otherwise <span class="mathjax-tex">\(f_0=f_0^*=0\)</span> is a trivial solution in the span of the data points. Since not all <span class="mathjax-tex">\(y_i\)</span> are zero <span class="mathjax-tex">\(f_0\not \in Z\)</span> and thus</p><div id="Equ27" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} {{\,\mathrm{codim}\,}}({{\,\mathrm{span}\,}}\{f_0,Z\}) = m-1 \end{aligned}$$</span></div></div><p>But since <span class="mathjax-tex">\(X^*={{\,\mathrm{span}\,}}\{x_i^*\}\)</span> and the dual map is a homeomorphism <i>X</i> is homeomorphic to a linear space of dimension <i>m</i>. This means that that <span class="mathjax-tex">\(X\cap {{\,\mathrm{span}\,}}\{f_0,Z\}\)</span> is homeomorphic to a one-dimensional space and hence in particular contains a nonzero element.</p>
                <p>Now fix such <span class="mathjax-tex">\(0\ne f\in X\cap {{\,\mathrm{span}\,}}\{f_0,Z\}\)</span>. As we noted earlier <i>f</i> being nonzero means that <span class="mathjax-tex">\(f\not \in {{\,\mathrm{span}\,}}\{f_0\}\)</span> and <span class="mathjax-tex">\(f\not \in Z\)</span>. Thus <span class="mathjax-tex">\(f=\lambda f_0 + \mu g\)</span> for <span class="mathjax-tex">\(\lambda ,\mu \ne 0, g\in Z\)</span>. By homogeneity of the dual map <span class="mathjax-tex">\(\lambda \cdot X=X\)</span> and so</p><div id="Equ28" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} f\in X\cap {{\,\mathrm{span}\,}}\{f_0,Z\}\Leftrightarrow \frac{1}{\lambda }f\in X\cap {{\,\mathrm{span}\,}}\{f_0,Z\} \end{aligned}$$</span></div></div><p>and thus</p><div id="Equ6" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \frac{1}{\lambda }f=f_0+\frac{\mu }{\lambda }g = f_0+\widetilde{g}\in X\cap {{\,\mathrm{span}\,}}\{f_0,Z\} \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (6)
                </div></div><p>with <span class="mathjax-tex">\(\widetilde{g}=\frac{\mu }{\lambda }g\in Z\)</span>.</p>
                <p>This means we have constructed an <span class="mathjax-tex">\(\overline{f_0}=f_0 + f_T\)</span> with dual element in the span of the data points and <span class="mathjax-tex">\(f_T\in Z\)</span> which means by definition of <i>Z</i> that <span class="mathjax-tex">\(\overline{f_0}\)</span> satisfies the interpolation constraints. It remains to show that in fact <span class="mathjax-tex">\(\overline{f_0}\)</span> is in norm at most as large as <span class="mathjax-tex">\(f_0\)</span>.</p>
                <p>To this end note that for all <span class="mathjax-tex">\(f_T\in Z\)</span> by definition <span class="mathjax-tex">\(\left[ {x^*},{f^*_T}\right] _{\mathcal {B}^*}=0\)</span> for all <span class="mathjax-tex">\(x^*\in X^*\)</span> and hence we see that for <span class="mathjax-tex">\(\overline{f_0}=f_0+f_T\in X\)</span> we get that</p><div id="Equ29" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \left[ {{(f_0+f_T)}^*},{f_T^*}\right] _{\mathcal {B}^*} = \left[ {f_T},{f_0+f_T}\right] _{\mathcal {B}} = 0 \end{aligned}$$</span></div></div><p>But by the equivalence with James orthogonality this means that</p>
                <p><span class="mathjax-tex">\({||}{(f_0+f_T) + t\cdot f_T}{||}&gt;{||}{f_0+f_T}{||}\)</span> for all <span class="mathjax-tex">\(t\ne 0\)</span> or equivalently</p><div id="Equ30" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} {||}{f_0+f_T}{||} = \min \limits _{t\in \mathbb {R}}{||}{f_0+t\cdot f_T}{||} \end{aligned}$$</span></div></div><p>In particular <span class="mathjax-tex">\({||}{\overline{f_0}}{||}={||}{f_0+f_T}{||}&lt;{||}{f_0+0\cdot f_T}{||}={||}{f_0}{||}\)</span>.</p>
                <p>But by Lemma <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10898-019-00767-0#FPar12">1</a> we know that for a function which is non-decreasing along tangential directions is non-decreasing in norm so <span class="mathjax-tex">\({||}{\overline{f_0}}{||}&lt;{||}{f_0}{||}\)</span> implies that <span class="mathjax-tex">\(\varOmega (\overline{f_0})\le \varOmega (f_0)\)</span> and so we have found a solution with dual element in the span of the data points as claimed. <span class="mathjax-tex">\(\square \)</span></p>
              <p>Using those two results we can now give the proof that admissible regularisers are almost radially symmetric in the sense of Theorem <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10898-019-00767-0#FPar11">2</a>.</p>
                <h3 class="c-article__sub-heading" id="FPar16">Proof of Theorem 2</h3>
                <p><i>Part 1: </i>(<span class="mathjax-tex">\(\varOmega \)</span><i>continuous in radial direction implies</i><span class="mathjax-tex">\(\varOmega \)</span><i>radially symmetric)</i></p>
                <p>We now show that instead of differentiability, the assumption that <span class="mathjax-tex">\(\varOmega \)</span> is continuous in radial direction is sufficient to conclude that it has to be radially symmetric. We prove this by contradiction. Assume <span class="mathjax-tex">\(\varOmega \)</span> is admissible but not radially symmetric. Then there exists a radius <i>r</i> so that <span class="mathjax-tex">\(\varOmega \)</span> is not constant on the circle with radius <i>r</i> and hence there are two points <i>f</i> and <i>g</i> so that, without loss of generality, <span class="mathjax-tex">\(\varOmega (f)&gt;\varOmega (g)\)</span>.</p>
                <p>But then by Lemma <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10898-019-00767-0#FPar12">1</a> for all <span class="mathjax-tex">\(1&lt;\lambda \in \mathbb {R}\)</span> we have <span class="mathjax-tex">\(\varOmega (\lambda g)\ge \varOmega (f)\)</span> and thus as <span class="mathjax-tex">\(\varOmega \)</span> non-negative and non-decreasing <span class="mathjax-tex">\(|\varOmega (\lambda g)-\varOmega (g)|\ge |\varOmega (f)-\varOmega (g)|&gt;0\)</span> contradicting radial continuity of <span class="mathjax-tex">\(\varOmega \)</span>. Hence <span class="mathjax-tex">\(\varOmega \)</span> has to be constant along every circle as claimed.</p>
                <p>
                  <i>Part 2: (Radial mollification preserves being nondecreasing in tangential directions)</i>
                </p>
                <p>The observation in part 1 is useful as we can easily radially mollify a given <span class="mathjax-tex">\(\varOmega \)</span> so that the property of being non-decreasing along tangential directions is preserved.</p>
                <p>Indeed let <span class="mathjax-tex">\(\rho \)</span> be a mollifier such that <span class="mathjax-tex">\(\rho :\mathbb {R}\rightarrow [0,\infty )\)</span> with support in <span class="mathjax-tex">\([-1,0]\)</span> and for each ray given by some <span class="mathjax-tex">\(f_0\in \mathcal {B}\)</span> of unit norm, define the mollified regulariser by</p><div id="Equ31" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \widetilde{\varOmega }(sf_0) = \int \limits _\mathbb {R}\rho (t)\varOmega \left( (s-t)f_0\right) \,\mathrm {d}{t} \end{aligned}$$</span></div></div><p>We thus obtain a radially mollified regulariser on <span class="mathjax-tex">\(\mathcal {B}\)</span> given by</p><div id="Equ32" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \widetilde{\varOmega }(f) = \widetilde{\varOmega }\left( {||}{f}{||}\frac{f}{{||}{f}{||}}\right)&amp;= \int \limits _\mathbb {R}\rho (t)\varOmega \left( ({||}{f}{||}-t)\frac{f}{{||}{f}{||}}\right) \,\mathrm {d}{t}\\&amp;= \int \limits _{-1}^0 \rho (t)\varOmega \left( ({||}{f}{||}-t)\frac{f}{{||}{f}{||}}\right) \,\mathrm {d}{t} \end{aligned}$$</span></div></div><p>We check that this function is still non-decreasing along tangential directions, i.e. we need to show that for <span class="mathjax-tex">\(f_T\)</span> s.t. <span class="mathjax-tex">\(\left[ {f_T},{f}\right] _{\mathcal {B}}=0\)</span> we still have</p><div id="Equ7" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \widetilde{\varOmega }(f+f_T)= &amp; {} \int \limits _{-1}^0 \rho (t)\varOmega \left( ({||}{f+f_T}{||}-t)\frac{f+f_T}{{||}{f+f_T}{||}}\right) \,\mathrm {d}{t}\nonumber \\\ge &amp; {} \int \limits _{-1}^0 \rho (t)\varOmega \left( \left( {||}{f}{||}-t\right) \frac{f}{{||}{f}{||}}\right) \,\mathrm {d}{t} = \widetilde{\varOmega }(f) \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (7)
                </div></div><p>Note that by Lemma <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10898-019-00767-0#FPar12">1</a> we have that <span class="mathjax-tex">\(\varOmega (({||}{f+f_T}{||}-t)\frac{f+f_T}{{||}{f+f_T}{||}}) \ge \varOmega (({||}{f}{||}-t)\frac{f}{{||}{f}{||}})\)</span> for all <span class="mathjax-tex">\(t\in [-1,0]\)</span> if <span class="mathjax-tex">\({||}{({||}{f+f_T}{||}-t)\frac{f+f_T}{{||}{f+f_T}{||}}}{||} \ge {||}{({||}{f}{||}-t)\frac{f}{{||}{f}{||}}}{||}\)</span> for all <span class="mathjax-tex">\(t\in [-1,0]\)</span>. But this is clear as it is equivalent to <span class="mathjax-tex">\({|}{{||}{f+f_T}{||}-t}{||}\ge {|}{{||}{f}{||}-t}{||}\)</span>. As <i>t</i> is non-positive we can drop the modulus to obtain that this happens if <span class="mathjax-tex">\({||}{f+f_T}{||}\ge {||}{f}{||}\)</span> which is just James orthogonality and thus follows from the fact that <span class="mathjax-tex">\(\left[ {f_T},{f}\right] _{\mathcal {B}}=0\)</span>. This proves that the integral estimate Eq. (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s10898-019-00767-0#Equ7">7</a>) indeed holds and hence the radially mollified <span class="mathjax-tex">\(\widetilde{\varOmega }\)</span> is indeed non-decreasing in tangential directions.</p>
                <p><i>Part 3:</i> (<span class="mathjax-tex">\(\varOmega \)</span><i>is as claimed)</i></p>
                <p>Putting these two observations together we obtain the result. By part 2 <span class="mathjax-tex">\(\widetilde{\varOmega }\)</span> is of the form <span class="mathjax-tex">\(\widetilde{\varOmega }(f)=h\left( \left[ {f},{f}\right] _{\mathcal {B}}\right) \)</span> for some continuous, non-decreasing <i>h</i>. But if we consider <span class="mathjax-tex">\(\varOmega \)</span> along any two distinct, fixed directions given by <span class="mathjax-tex">\(f_1,f_2\in \mathcal {B}\)</span>, <span class="mathjax-tex">\(f_1\ne f_2\)</span>, <span class="mathjax-tex">\({||}{f_1}{||}={||}{f_2}{||}=1\)</span> as <span class="mathjax-tex">\(\varOmega (t\cdot f_i) = h_{f_i}\left( \left[ {t\cdot f_i},{t\cdot f_i}\right] _{\mathcal {B}}\right) \)</span> then the mollifications of both <span class="mathjax-tex">\(h_{f_1}\)</span> and <span class="mathjax-tex">\(h_{f_2}\)</span> must equal <i>h</i> so <span class="mathjax-tex">\(h_{f_1}=h_{f_2}\)</span> almost everywhere. Further by continuity of <i>h</i> they can only differ in points of discontinuity of <span class="mathjax-tex">\(h_{f_1}\)</span> and <span class="mathjax-tex">\(h_{f_2}\)</span>. As each <span class="mathjax-tex">\(h_{f_i}\)</span> is a monotone function on the positive real line it can only have countably many points of discontinuity. Clearly as above bounds are only making statements about values outside a given circle and <i>h</i> is itself monotone, each <span class="mathjax-tex">\(h_{f_i}\)</span> is free to attain any value within the monotonicity constraint in those points of discontinuity. This shows that <span class="mathjax-tex">\(\varOmega \)</span> is of the claimed form. <span class="mathjax-tex">\(\square \)</span></p>
              
                <h3 class="c-article__sub-heading" id="FPar17">Remark 2</h3>
                <p>We see that everything we say about <span class="mathjax-tex">\(\varOmega \)</span> in this section relies crucially on the observation that it being admissible is a statement about its behaviour along tangents as stated in Lemma <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10898-019-00767-0#FPar14">2</a>. But there is in fact no tangent into the complex plane, i.e. for fixed <span class="mathjax-tex">\(\hat{f}\)</span> there is no tangent that intersects the ray <span class="mathjax-tex">\(\{t\cdot e^{i\theta }\cdot \hat{f}\,:\,t\in \mathbb {R}\}\)</span> for any <span class="mathjax-tex">\(\theta \)</span>. Likewise it is not possible to reach any point along said ray via an “out and back” argument as in part 1 of the proof of Lemma <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10898-019-00767-0#FPar12">1</a>. For this reason it is currently not clear whether one can say anything about the situation in complex vector spaces.</p>
              </div></div></section><section aria-labelledby="Sec5" data-title="The solution is determined by the space"><div class="c-article-section" id="Sec5-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Sec5">The solution is determined by the space</h2><div class="c-article-section__content" id="Sec5-content"><p>First of all, while it has been known that for regularisers which are a strictly increasing function of the norm every solution is within the linear span of the data, the proofs in Sect. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="/article/10.1007/s10898-019-00767-0#Sec4">3</a> show immediately that something stronger can be said. For a regularised interpolation problem with an admissible regulariser to have a solution which is not in the linear span of the data the regulariser must have a flat region and the solution then has to lie within the flat region.</p><p>But there is more to be said, in fact it turns out that for admissible regularisers the set of solutions in the linear span is independent of the regulariser.</p><p>In [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Micchelli, C.A., Pontil, M.: A function representation for learning in banach spaces. In: Shawe-Taylor, J., Singer, Y. (eds.) Learning Theory, pp. 255–269. Springer, Berlin (2004)" href="/article/10.1007/s10898-019-00767-0#ref-CR12" id="ref-link-section-d15187e15592">12</a>] Micchelli and Pontil consider the minimal norm interpolation problem</p><div id="Equ33" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \inf \{{||}{x}{||}_X \,:\,x\in X, L_i(x) = y_i\,\forall i\in \mathbb {N}_m\} \end{aligned}$$</span></div></div><p>where <i>X</i> is a Banach space and <span class="mathjax-tex">\(L_i\)</span> are continuous linear functionals on <i>X</i>. Hence this agrees with Eq. (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s10898-019-00767-0#Equ3">3</a>) for <span class="mathjax-tex">\(h(t)=\sqrt{t}\)</span> i.e. <span class="mathjax-tex">\(\varOmega (f)={(\left[ {x},{x}\right] _{\mathcal {B}})}^{\frac{1}{2}}\)</span> and <span class="mathjax-tex">\(X=\mathcal {B}\)</span> a uniformly convex, uniformly smooth Banach space, giving the minimal norm interpolation problem</p><div id="Equ8" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \min \{{||}{f}{||}_\mathcal {B}\,:\,f\in \mathcal {B}, x^*_i(f) = \left[ {f},{x_i}\right] _{\mathcal {B}} = y_i\,\forall i\in \mathbb {N}_m\} \end{aligned}$$</span></div><div class="c-article-equation__number">
                    (8)
                </div></div><p>This leads to the following result.</p>
                <h3 class="c-article__sub-heading" id="FPar18">Theorem 3</h3>
                <p>Let <span class="mathjax-tex">\(\varOmega \)</span> be admissible. Then any <span class="mathjax-tex">\(f_0\)</span> which is such that <span class="mathjax-tex">\(f^*_0 = \sum \nolimits _{i=1}^m c_i x^*_i\)</span> is a solution of Eq. (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s10898-019-00767-0#Equ3">3</a>) if and only if it is a solution of Eq. (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s10898-019-00767-0#Equ8">8</a>).</p>
              <p>The proof of this result relies on the following result which was proved by Micchelli and Pontil in [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Micchelli, C.A., Pontil, M.: A function representation for learning in banach spaces. In: Shawe-Taylor, J., Singer, Y. (eds.) Learning Theory, pp. 255–269. Springer, Berlin (2004)" href="/article/10.1007/s10898-019-00767-0#ref-CR12" id="ref-link-section-d15187e16170">12</a>].</p>
                <h3 class="c-article__sub-heading" id="FPar19">Proposition 3</h3>
                <p>(Theorem 1 in [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Micchelli, C.A., Pontil, M.: A function representation for learning in banach spaces. In: Shawe-Taylor, J., Singer, Y. (eds.) Learning Theory, pp. 255–269. Springer, Berlin (2004)" href="/article/10.1007/s10898-019-00767-0#ref-CR12" id="ref-link-section-d15187e16180">12</a>]) <span class="mathjax-tex">\(f_0\)</span> is a solution of Eq. (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s10898-019-00767-0#Equ8">8</a>) if and only if it satisfies the constraints <span class="mathjax-tex">\(x^*_i(f_0)=y_i\)</span> and there is a linear combination of the continuous linear functionals defining the problem which peaks at <span class="mathjax-tex">\(f_0\)</span>, i.e. there exists <span class="mathjax-tex">\((c_1,\ldots ,c_m)\in \mathbb {R}^m\)</span> such that</p><div id="Equ34" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \sum \limits _{i=1}^m c_i x^*_i(f_0) = \left\| \sum \limits _{i=1}^m c_ix^*_i\right\| _{\mathcal {B}^*}\cdot {||}{f_0}{||}_\mathcal {B}\end{aligned}$$</span></div></div>
              <p>Using this result it is easy to proof Theorem <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10898-019-00767-0#FPar18">3</a>.</p>
                <h3 class="c-article__sub-heading" id="FPar20">Proof of Theorem 3</h3>
                <p><i>Part 1: (A solution of Eq.</i> (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s10898-019-00767-0#Equ3">3</a>) <i>is a solution of Eq.</i> (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s10898-019-00767-0#Equ8">8</a>))</p>
                <p>Assume that <span class="mathjax-tex">\(f_0\)</span> is a solution of Eq. (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s10898-019-00767-0#Equ3">3</a>) such that <span class="mathjax-tex">\(f^*_0 = \sum \nolimits _{i=1}^mc_i x^*_i\)</span>. Then trivially <span class="mathjax-tex">\(f_0\)</span> satisfies the interpolation constraints and by definition</p><div id="Equ35" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} f^*_0(f_0) = \left[ {f_0},{f_0}\right] _{\mathcal {B}}={||}{f_0}{||}_\mathcal {B}^2={||}{f^*_0}{||}_{\mathcal {B}^*}\cdot {||}{f_0}{||}_\mathcal {B}\end{aligned}$$</span></div></div><p>so <span class="mathjax-tex">\(f^*_0\)</span>, which is a linear combination of the continuous linear problems defining the problem, peaks at <span class="mathjax-tex">\(f_0\)</span>. Thus by Proposition <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10898-019-00767-0#FPar19">3</a><span class="mathjax-tex">\(f_0\)</span> is a solution of Eq. (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s10898-019-00767-0#Equ8">8</a>).</p>
                <p><i>Part 2: (A solution of Eq.</i> (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s10898-019-00767-0#Equ8">8</a>) <i>is a solution of Eq.</i> (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s10898-019-00767-0#Equ3">3</a>))</p>
                <p>Assume <span class="mathjax-tex">\(f_0\)</span> is a solution of Eq. (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s10898-019-00767-0#Equ8">8</a>). Then by Eq. (<a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="/article/10.1007/s10898-019-00767-0#FPar19">3</a>) there exists</p>
                <p><span class="mathjax-tex">\((c_1,\ldots ,c_m)\in \mathbb {R}^m\)</span> such that the functional <span class="mathjax-tex">\(\sum \nolimits _{i=1}^m c_i x^*_i\)</span> peaks at <span class="mathjax-tex">\(f_0\)</span>, i.e.</p><div id="Equ36" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \sum \limits _{i=1}^m c_i x^*_i(f_0) = \left\| \sum \limits _{i=1}^m c_i x^*_i\right\| _{\mathcal {B}^*}\cdot {||}{f_0}{||}_\mathcal {B}\end{aligned}$$</span></div></div><p>But then for any <span class="mathjax-tex">\(g\in Z=\{f\in \mathcal {B}\,:\,x^*_i(f)=\left[ {f},{x_i}\right] _{\mathcal {B}}=0,\,\forall i=1,\ldots ,m\}\)</span> we have that</p><div id="Equ37" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \left\| \sum \limits _{i=1}^m c_i x^*_i\right\| _{\mathcal {B}^*}\cdot {||}{f_0}{||}_\mathcal {B}= \sum \limits _{i=1}^m c_i x^*_i(f_0) = \sum \limits _{i=1}^m c_i x^*_i(f_0 + g) &lt; \left\| \sum \limits _{i=1}^m c_i x^*_i\right\| _{\mathcal {B}^*}\cdot {||}{f_0+g}{||}_\mathcal {B}\end{aligned}$$</span></div></div><p>where the last inequality is strict because <span class="mathjax-tex">\(\sum \nolimits _{i=1}^m c_i x^*_i\)</span> peaks at <span class="mathjax-tex">\(f_0\)</span> and by strict convexity it peaks at a unique point. But this inequality shows that</p><div id="Equ38" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} {||}{f_0}{||}_\mathcal {B}&lt; {||}{f_0+g}{||}_\mathcal {B}\end{aligned}$$</span></div></div><p>for all <span class="mathjax-tex">\(g\in Z\)</span> and thus as <span class="mathjax-tex">\(\varOmega \)</span> is admissible also</p><div id="Equ39" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} \varOmega (f_0) \le \varOmega (f_0+g) \end{aligned}$$</span></div></div><p>and <span class="mathjax-tex">\(f_0\)</span> is a solution of Eq. (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="/article/10.1007/s10898-019-00767-0#Equ3">3</a>). <span class="mathjax-tex">\(\square \)</span></p>
              <p>This result shows that any admissible regulariser on a uniformly convex and uniformly smooth Banach space has a unique solution in the linear span of the data and the solution is the same for every admissible regulariser. This in particular means that it is the choice of the function space, and only the choice of the space, which determines the solution of the problem. We are thus free to work with whichever regulariser is most convenient in application. Computationally in many cases this is likely going to be <span class="mathjax-tex">\(\frac{1}{2}{||}{\cdot }{||}^2\)</span>, for theoretical results other regularisers may be more suitable, such as in the afore mentioned paper [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Micchelli, C.A., Pontil, M.: A function representation for learning in banach spaces. In: Shawe-Taylor, J., Singer, Y. (eds.) Learning Theory, pp. 255–269. Springer, Berlin (2004)" href="/article/10.1007/s10898-019-00767-0#ref-CR12" id="ref-link-section-d15187e18131">12</a>] which heavily relies on a duality between the norm of the space and its continuous linear functionals.</p></div></div></section>
                        
                    

                    <section aria-labelledby="Bib1" data-title="References"><div class="c-article-section" id="Bib1-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="Bib1">References</h2><div class="c-article-section__content" id="Bib1-content"><div data-container-section="references"><ol class="c-article-references"><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="A. Argyriou, CA. Micchelli, M. Pontil, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Argyriou, A., Micchelli, C.A., Pontil, M.: When is there a representer theorem? vector versus matrix regulariz" /><span class="c-article-references__counter">1.</span><p class="c-article-references__text" id="ref-CR1">Argyriou, A., Micchelli, C.A., Pontil, M.: When is there a representer theorem? vector versus matrix regularizers. J. Mach. Learn. Res. <b>10</b>, 2507–2529 (2009)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=2576327" aria-label="View reference 1 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?1235.68128" aria-label="View reference 1 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 1 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=When%20is%20there%20a%20representer%20theorem%3F%20vector%20versus%20matrix%20regularizers&amp;journal=J.%20Mach.%20Learn.%20Res.&amp;volume=10&amp;pages=2507-2529&amp;publication_year=2009&amp;author=Argyriou%2CA&amp;author=Micchelli%2CCA&amp;author=Pontil%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="H. Brezis, " /><meta itemprop="datePublished" content="2011" /><meta itemprop="headline" content="Brezis, H.: Functional Analysis, Sobolev Spaces and Partial Differential Equations. Universitext, 1st edn. Spr" /><span class="c-article-references__counter">2.</span><p class="c-article-references__text" id="ref-CR2">Brezis, H.: Functional Analysis, Sobolev Spaces and Partial Differential Equations. Universitext, 1st edn. Springer, New York (2011)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 2 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Functional%20Analysis%2C%20Sobolev%20Spaces%20and%20Partial%20Differential%20Equations&amp;publication_year=2011&amp;author=Brezis%2CH">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="DD. Cox, F. O’Sullivan, " /><meta itemprop="datePublished" content="1990" /><meta itemprop="headline" content="Cox, D.D., O’Sullivan, F.: Asymptotic analysis of penalized likelihood and related estimators. Ann. Stat. 18(4" /><span class="c-article-references__counter">3.</span><p class="c-article-references__text" id="ref-CR3">Cox, D.D., O’Sullivan, F.: Asymptotic analysis of penalized likelihood and related estimators. Ann. Stat. <b>18</b>(4), 1676–1695 (1990). <a href="https://doi.org/10.1214/aos/1176347872">https://doi.org/10.1214/aos/1176347872</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=1074429" aria-label="View reference 3 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1214%2Faos%2F1176347872" aria-label="View reference 3">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?0719.62051" aria-label="View reference 3 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 3 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Asymptotic%20analysis%20of%20penalized%20likelihood%20and%20related%20estimators&amp;journal=Ann.%20Stat.&amp;doi=10.1214%2Faos%2F1176347872&amp;volume=18&amp;issue=4&amp;pages=1676-1695&amp;publication_year=1990&amp;author=Cox%2CDD&amp;author=O%E2%80%99Sullivan%2CF">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="F. Cucker, S. Smale, " /><meta itemprop="datePublished" content="2001" /><meta itemprop="headline" content="Cucker, F., Smale, S.: On the mathematical foundations of learning. Bull. Am. Math. Soc. 39(1), 1–49 (2001)" /><span class="c-article-references__counter">4.</span><p class="c-article-references__text" id="ref-CR4">Cucker, F., Smale, S.: On the mathematical foundations of learning. Bull. Am. Math. Soc. <b>39</b>(1), 1–49 (2001)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=1864085" aria-label="View reference 4 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1090%2FS0273-0979-01-00923-5" aria-label="View reference 4">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?0983.68162" aria-label="View reference 4 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 4 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=On%20the%20mathematical%20foundations%20of%20learning&amp;journal=Bull.%20Am.%20Math.%20Soc.&amp;volume=39&amp;issue=1&amp;pages=1-49&amp;publication_year=2001&amp;author=Cucker%2CF&amp;author=Smale%2CS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="SS. Dragomir, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Dragomir, S.S.: Semi-inner Products and Applications. Nova Science Publishers, Hauppauge (2004)" /><span class="c-article-references__counter">5.</span><p class="c-article-references__text" id="ref-CR5">Dragomir, S.S.: Semi-inner Products and Applications. Nova Science Publishers, Hauppauge (2004)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 5 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Semi-inner%20Products%20and%20Applications&amp;publication_year=2004&amp;author=Dragomir%2CSS">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="JR. Giles, " /><meta itemprop="datePublished" content="1967" /><meta itemprop="headline" content="Giles, J.R.: Classes of semi-inner-product spaces. Trans. Am. Math. Soc. 129(3), 436–446 (1967)" /><span class="c-article-references__counter">6.</span><p class="c-article-references__text" id="ref-CR6">Giles, J.R.: Classes of semi-inner-product spaces. Trans. Am. Math. Soc. <b>129</b>(3), 436–446 (1967)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=217574" aria-label="View reference 6 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1090%2FS0002-9947-1967-0217574-1" aria-label="View reference 6">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?0157.20103" aria-label="View reference 6 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 6 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Classes%20of%20semi-inner-product%20spaces&amp;journal=Trans.%20Am.%20Math.%20Soc.&amp;volume=129&amp;issue=3&amp;pages=436-446&amp;publication_year=1967&amp;author=Giles%2CJR">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="RC. James, " /><meta itemprop="datePublished" content="1947" /><meta itemprop="headline" content="James, R.C.: Orthogonality and linear functionals in normed linear spaces. Trans. Am. Math. Soc. 61(2), 265–29" /><span class="c-article-references__counter">7.</span><p class="c-article-references__text" id="ref-CR7">James, R.C.: Orthogonality and linear functionals in normed linear spaces. Trans. Am. Math. Soc. <b>61</b>(2), 265–292 (1947)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=21241" aria-label="View reference 7 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1090%2FS0002-9947-1947-0021241-4" aria-label="View reference 7">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 7 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Orthogonality%20and%20linear%20functionals%20in%20normed%20linear%20spaces&amp;journal=Trans.%20Am.%20Math.%20Soc.&amp;volume=61&amp;issue=2&amp;pages=265-292&amp;publication_year=1947&amp;author=James%2CRC">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="G. Kimeldorf, G. Wahba, " /><meta itemprop="datePublished" content="1971" /><meta itemprop="headline" content="Kimeldorf, G., Wahba, G.: Some results on Tchebycheffian spline functions. J. Math. Anal. Appl. 33(1), 82–95 (" /><span class="c-article-references__counter">8.</span><p class="c-article-references__text" id="ref-CR8">Kimeldorf, G., Wahba, G.: Some results on Tchebycheffian spline functions. J. Math. Anal. Appl. <b>33</b>(1), 82–95 (1971). <a href="https://doi.org/10.1016/0022-247X(71)90184-3">https://doi.org/10.1016/0022-247X(71)90184-3</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=290013" aria-label="View reference 8 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1016%2F0022-247X%2871%2990184-3" aria-label="View reference 8">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?0201.39702" aria-label="View reference 8 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 8 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Some%20results%20on%20Tchebycheffian%20spline%20functions&amp;journal=J.%20Math.%20Anal.%20Appl.&amp;doi=10.1016%2F0022-247X%2871%2990184-3&amp;volume=33&amp;issue=1&amp;pages=82-95&amp;publication_year=1971&amp;author=Kimeldorf%2CG&amp;author=Wahba%2CG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="G. Köthe, " /><meta itemprop="datePublished" content="1983" /><meta itemprop="headline" content="Köthe, G.: Topological Vectorspaces I, Grundlehren der Mathematischen Wissenschaften, vol. 159. Springer, Berl" /><span class="c-article-references__counter">9.</span><p class="c-article-references__text" id="ref-CR9">Köthe, G.: Topological Vectorspaces I, Grundlehren der Mathematischen Wissenschaften, vol. 159. Springer, Berlin (1983)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 9 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Topological%20Vectorspaces%20I%2C%20Grundlehren%20der%20Mathematischen%20Wissenschaften&amp;publication_year=1983&amp;author=K%C3%B6the%2CG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="J. Lindenstrauss, L. Tzafriri, " /><meta itemprop="datePublished" content="1979" /><meta itemprop="headline" content="Lindenstrauss, J., Tzafriri, L.: Classical Banach Spaces II: Function Spaces, Ergebnisse der Mathematik und ih" /><span class="c-article-references__counter">10.</span><p class="c-article-references__text" id="ref-CR10">Lindenstrauss, J., Tzafriri, L.: Classical Banach Spaces II: Function Spaces, Ergebnisse der Mathematik und ihrer Grenzgebiete, vol. 97. Springer, Berlin (1979)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 10 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Classical%20Banach%20Spaces%20II%3A%20Function%20Spaces%2C%20Ergebnisse%20der%20Mathematik%20und%20ihrer%20Grenzgebiete&amp;publication_year=1979&amp;author=Lindenstrauss%2CJ&amp;author=Tzafriri%2CL">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="G. Lumer, " /><meta itemprop="datePublished" content="1961" /><meta itemprop="headline" content="Lumer, G.: Semi-inner-product spaces. Trans. Am. Math. Soc. 100(1), 29–43 (1961)" /><span class="c-article-references__counter">11.</span><p class="c-article-references__text" id="ref-CR11">Lumer, G.: Semi-inner-product spaces. Trans. Am. Math. Soc. <b>100</b>(1), 29–43 (1961)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=133024" aria-label="View reference 11 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1090%2FS0002-9947-1961-0133024-2" aria-label="View reference 11">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?0102.32701" aria-label="View reference 11 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 11 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Semi-inner-product%20spaces&amp;journal=Trans.%20Am.%20Math.%20Soc.&amp;volume=100&amp;issue=1&amp;pages=29-43&amp;publication_year=1961&amp;author=Lumer%2CG">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="CA. Micchelli, M. Pontil, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Micchelli, C.A., Pontil, M.: A function representation for learning in banach spaces. In: Shawe-Taylor, J., Si" /><span class="c-article-references__counter">12.</span><p class="c-article-references__text" id="ref-CR12">Micchelli, C.A., Pontil, M.: A function representation for learning in banach spaces. In: Shawe-Taylor, J., Singer, Y. (eds.) Learning Theory, pp. 255–269. Springer, Berlin (2004)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 12 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Learning%20Theory&amp;pages=255-269&amp;publication_year=2004&amp;author=Micchelli%2CCA&amp;author=Pontil%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="CA. Micchelli, M. Pontil, " /><meta itemprop="datePublished" content="2005" /><meta itemprop="headline" content="Micchelli, C.A., Pontil, M.: Learning the kernel function via regularization. J. Mach. Lear. Res. 6, 1099–1125" /><span class="c-article-references__counter">13.</span><p class="c-article-references__text" id="ref-CR13">Micchelli, C.A., Pontil, M.: Learning the kernel function via regularization. J. Mach. Lear. Res. <b>6</b>, 1099–1125 (2005)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=2249850" aria-label="View reference 13 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?1222.68265" aria-label="View reference 13 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 13 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Learning%20the%20kernel%20function%20via%20regularization&amp;journal=J.%20Mach.%20Lear.%20Res.&amp;volume=6&amp;pages=1099-1125&amp;publication_year=2005&amp;author=Micchelli%2CCA&amp;author=Pontil%2CM">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="B. Schölkopf, R. Herbrich, AJ. Smola, " /><meta itemprop="datePublished" content="2001" /><meta itemprop="headline" content="Schölkopf, B., Herbrich, R., Smola, A.J.: A generalized representer theorem. In: Helmbold, D., Williamson, B. " /><span class="c-article-references__counter">14.</span><p class="c-article-references__text" id="ref-CR14">Schölkopf, B., Herbrich, R., Smola, A.J.: A generalized representer theorem. In: Helmbold, D., Williamson, B. (eds.) Computational Learning Theory, pp. 416–426. Springer, Berlin (2001)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 14 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Computational%20Learning%20Theory&amp;pages=416-426&amp;publication_year=2001&amp;author=Sch%C3%B6lkopf%2CB&amp;author=Herbrich%2CR&amp;author=Smola%2CAJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="B. Schölkopf, AJ. Smola, " /><meta itemprop="datePublished" content="2002" /><meta itemprop="headline" content="Schölkopf, B., Smola, A.J.: Learning with Kernels. MIT Press, Cambridge (2002)" /><span class="c-article-references__counter">15.</span><p class="c-article-references__text" id="ref-CR15">Schölkopf, B., Smola, A.J.: Learning with Kernels. MIT Press, Cambridge (2002)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 15 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Learning%20with%20Kernels&amp;publication_year=2002&amp;author=Sch%C3%B6lkopf%2CB&amp;author=Smola%2CAJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/Book"><meta itemprop="author" content="J. Shawe-Taylor, N. Cristianini, " /><meta itemprop="datePublished" content="2004" /><meta itemprop="headline" content="Shawe-Taylor, J., Cristianini, N.: Kernel Methods for Pattern Analysis. Cambridge University Press, Cambridge " /><span class="c-article-references__counter">16.</span><p class="c-article-references__text" id="ref-CR16">Shawe-Taylor, J., Cristianini, N.: Kernel Methods for Pattern Analysis. Cambridge University Press, Cambridge (2004). <a href="https://doi.org/10.1017/CBO9780511809682">https://doi.org/10.1017/CBO9780511809682</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 16 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Kernel%20Methods%20for%20Pattern%20Analysis&amp;publication_year=2004&amp;author=Shawe-Taylor%2CJ&amp;author=Cristianini%2CN">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="JA. Smola, B. Schölkopf, " /><meta itemprop="datePublished" content="1998" /><meta itemprop="headline" content="Smola, J.A., Schölkopf, B.: On a kernel-based method for pattern recognition, regression, approximation, and o" /><span class="c-article-references__counter">17.</span><p class="c-article-references__text" id="ref-CR17">Smola, J.A., Schölkopf, B.: On a kernel-based method for pattern recognition, regression, approximation, and operator inversion. Algorithmica <b>22</b>(1), 211–231 (1998). <a href="https://doi.org/10.1007/PL00013831">https://doi.org/10.1007/PL00013831</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=1637511" aria-label="View reference 17 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2FPL00013831" aria-label="View reference 17">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?0910.68189" aria-label="View reference 17 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 17 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=On%20a%20kernel-based%20method%20for%20pattern%20recognition%2C%20regression%2C%20approximation%2C%20and%20operator%20inversion&amp;journal=Algorithmica&amp;doi=10.1007%2FPL00013831&amp;volume=22&amp;issue=1&amp;pages=211-231&amp;publication_year=1998&amp;author=Smola%2CJA&amp;author=Sch%C3%B6lkopf%2CB">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="H. Zhang, Y. Xu, J. Zhang, " /><meta itemprop="datePublished" content="2009" /><meta itemprop="headline" content="Zhang, H., Xu, Y., Zhang, J.: reproducing kernel banach spaces for machine learning. J. Mach. Learn. Res. 10, " /><span class="c-article-references__counter">18.</span><p class="c-article-references__text" id="ref-CR18">Zhang, H., Xu, Y., Zhang, J.: reproducing kernel banach spaces for machine learning. J. Mach. Learn. Res. <b>10</b>, 2741–2775 (2009)</p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=2579912" aria-label="View reference 18 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?1235.68217" aria-label="View reference 18 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 18 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=reproducing%20kernel%20banach%20spaces%20for%20machine%20learning&amp;journal=J.%20Mach.%20Learn.%20Res.&amp;volume=10&amp;pages=2741-2775&amp;publication_year=2009&amp;author=Zhang%2CH&amp;author=Xu%2CY&amp;author=Zhang%2CJ">
                    Google Scholar</a> 
                </p></li><li class="c-article-references__item js-c-reading-companion-references-item" itemprop="citation" itemscope="itemscope" itemtype="http://schema.org/ScholarlyArticle"><meta itemprop="author" content="H. Zhang, J. Zhang, " /><meta itemprop="datePublished" content="2012" /><meta itemprop="headline" content="Zhang, H., Zhang, J.: Regularized learning in banach spaces as an optimization problem: representer theorems. " /><span class="c-article-references__counter">19.</span><p class="c-article-references__text" id="ref-CR19">Zhang, H., Zhang, J.: Regularized learning in banach spaces as an optimization problem: representer theorems. J. Global Optim. <b>54</b>(2), 235–250 (2012). <a href="https://doi.org/10.1007/s10898-010-9575-z">https://doi.org/10.1007/s10898-010-9575-z</a>
                        </p><p class="c-article-references__links u-hide-print"><a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.ams.org/mathscinet-getitem?mr=2979626" aria-label="View reference 19 on MathSciNet">MathSciNet</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="https://doi.org/10.1007%2Fs10898-010-9575-z" aria-label="View reference 19">Article</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" href="http://www.emis.de/MATH-item?1281.90088" aria-label="View reference 19 on MATH">MATH</a> 
    <a data-track="click" data-track-action="outbound reference" data-track-label="link" aria-label="Search for reference 19 on Google Scholar" href="http://scholar.google.com/scholar_lookup?&amp;title=Regularized%20learning%20in%20banach%20spaces%20as%20an%20optimization%20problem%3A%20representer%20theorems&amp;journal=J.%20Global%20Optim.&amp;doi=10.1007%2Fs10898-010-9575-z&amp;volume=54&amp;issue=2&amp;pages=235-250&amp;publication_year=2012&amp;author=Zhang%2CH&amp;author=Zhang%2CJ">
                    Google Scholar</a> 
                </p></li></ol><p class="c-article-references__download u-hide-print"><a data-track="click" data-track-action="download citation references" data-track-label="link" href="/article/10.1007/s10898-019-00767-0-references.ris">Download references<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section><section aria-labelledby="Ack1"><div class="c-article-section" id="Ack1-section"><div class="c-article-section__content" id="Ack1-content"></div></div></section><section aria-labelledby="author-information" data-title="Author information"><div class="c-article-section" id="author-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="author-information">Author information</h2><div class="c-article-section__content" id="author-information-content"><h3 class="c-article__sub-heading" id="affiliations">Affiliations</h3><ol class="c-article-author-affiliation__list"><li id="Aff1"><p class="c-article-author-affiliation__address">Mathematical Institute, University of Oxford, Andrew Wiles Building, Radcliffe Observatory Quarter Woodstock Road, Oxford, OX2 6GG, UK</p><p class="c-article-author-affiliation__authors-list">Kevin Schlegel</p></li></ol><div class="js-hide u-hide-print" data-test="author-info"><span class="c-article__sub-heading">Authors</span><ol class="c-article-authors-search u-list-reset"><li id="auth-Kevin-Schlegel"><span class="c-article-authors-search__title u-h3 js-search-name">Kevin Schlegel</span><div class="c-article-authors-search__list"><div class="c-article-authors-search__item c-article-authors-search__list-item--left"><a href="/search?dc.creator=&#34;Kevin+Schlegel&#34;" class="c-article-button" data-track="click" data-track-action="author link - publication" data-track-label="link">View author publications</a></div><div class="c-article-authors-search__item c-article-authors-search__list-item--right"><p class="search-in-title-js c-article-authors-search__text">You can also search for this author in
                        <span class="c-article-identifiers"><a class="c-article-identifiers__item" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Kevin+Schlegel" data-track="click" data-track-action="author link - pubmed" data-track-label="link">PubMed</a><span class="u-hide"> </span><a class="c-article-identifiers__item" href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Kevin+Schlegel%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link">Google Scholar</a></span></p></div></div></li></ol></div><h3 class="c-article__sub-heading" id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" rel="nofollow" href="/article/10.1007/s10898-019-00767-0/email/correspondent/c1/new">Kevin Schlegel</a>.</p></div></div></section><section aria-labelledby="additional-information" data-title="Additional information"><div class="c-article-section" id="additional-information-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="additional-information">Additional information</h2><div class="c-article-section__content" id="additional-information-content"><h3 class="c-article__sub-heading">Publisher's Note</h3><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></div></div></section><section aria-labelledby="appendices"><div class="c-article-section" id="appendices-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="appendices">Appendix</h2><div class="c-article-section__content" id="appendices-content"><h3 class="c-article__sub-heading u-visually-hidden" id="App1">Appendix</h3>
                  <h3 class="c-article__sub-heading" id="FPar21">Proof of Proposition 2</h3>
                  <p>We begin by showing norm-to-weak continuity and subsequently extend it to norm-to-norm continuity.</p>
                  <p>Since <span class="mathjax-tex">\(\mathcal {B}\)</span> is reflexive the weak and weak<span class="mathjax-tex">\(*\)</span> topologies on <span class="mathjax-tex">\(\mathcal {B}^*\)</span> coincide, so we need to show that if <span class="mathjax-tex">\(x_n\rightarrow x\)</span> in norm then <span class="mathjax-tex">\(x^*_n(y)\rightarrow x^*(y)\)</span> for all <span class="mathjax-tex">\(y\in \mathcal {B}\)</span>.</p>
                  <p>Now as <span class="mathjax-tex">\({||}{x^*_n}{||}_{\mathcal {B}^*}={||}{x_n}{||}_\mathcal {B}\)</span> the sequence <span class="mathjax-tex">\((x^*_n)\)</span> is bounded so it has a weakly<span class="mathjax-tex">\(*\)</span> convergent subsequence <span class="mathjax-tex">\(x^*_{n_k}\overset{*}{\rightharpoonup }\overline{x}^*\)</span>. By [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Brezis, H.: Functional Analysis, Sobolev Spaces and Partial Differential Equations. Universitext, 1st edn. Springer, New York (2011)" href="/article/10.1007/s10898-019-00767-0#ref-CR2" id="ref-link-section-d15187e18571">2</a>] proposition 3.13 (iv) we then have</p><div id="Equ40" class="c-article-equation"><div class="c-article-equation__content"><span class="mathjax-tex">$$\begin{aligned} x^*_{n_k}\left( x_{n_k}\right) \underset{{k}\rightarrow {\infty }}{\longrightarrow }\overline{x}^*(x) \end{aligned}$$</span></div></div><p>But <span class="mathjax-tex">\(x^*_{n_k}(x_{n_k})={||}{x_{n_k}}{||}^2\rightarrow {||}{x}{||}^2\)</span> and so <span class="mathjax-tex">\(\overline{x}^*(x)={||}{x}{||}^2\)</span>. By [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Brezis, H.: Functional Analysis, Sobolev Spaces and Partial Differential Equations. Universitext, 1st edn. Springer, New York (2011)" href="/article/10.1007/s10898-019-00767-0#ref-CR2" id="ref-link-section-d15187e18867">2</a>] proposition 3.13 (iii) we further know that <span class="mathjax-tex">\({||}{\overline{x}^*}{||}\le \liminf {||}{x^*_{n_k}}{||}={||}{x}{||}\)</span>. By strict convexity there is a unique element with those two properties and hence <span class="mathjax-tex">\(\overline{x}^*=x^*\)</span>.</p>
                  <p>Note that this means that for any subsequence there exists a further subsequence converging to a unique limit. This means that in fact the entire sequence converges to this unique limit. Hence indeed <span class="mathjax-tex">\(x^*_n\rightharpoonup x^*\)</span> as claimed.</p>
                  <p>Having established norm-to-weak continuity one can easily extend it to norm-to-norm continuity using [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Brezis, H.: Functional Analysis, Sobolev Spaces and Partial Differential Equations. Universitext, 1st edn. Springer, New York (2011)" href="/article/10.1007/s10898-019-00767-0#ref-CR2" id="ref-link-section-d15187e19067">2</a>] proposition 3.32. Since <span class="mathjax-tex">\(\limsup {||}{x^*_n}{||}_{\mathcal {B}^*}={||}{x}{||}_\mathcal {B}={||}{x^*}{||}_{\mathcal {B}^*}\)</span> all the assumptions of proposition 3.32 in [<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Brezis, H.: Functional Analysis, Sobolev Spaces and Partial Differential Equations. Universitext, 1st edn. Springer, New York (2011)" href="/article/10.1007/s10898-019-00767-0#ref-CR2" id="ref-link-section-d15187e19205">2</a>] are satisfied and so indeed <span class="mathjax-tex">\(x^*_n\rightarrow x^*\)</span> in norm. <span class="mathjax-tex">\(\square \)</span></p>
                </div></div></section><section aria-labelledby="rightslink" data-title="Rights and permissions"><div class="c-article-section" id="rightslink-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="rightslink">Rights and permissions</h2><div class="c-article-section__content" id="rightslink-content">
                <p><b>Open Access</b> This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made.</p>
              <p class="c-article-rights"><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=When%20is%20there%20a%20representer%20theorem%3F&amp;author=Kevin%20Schlegel&amp;contentID=10.1007%2Fs10898-019-00767-0&amp;copyright=The%20Author%28s%29&amp;publication=0925-5001&amp;publicationDate=2019-04-08&amp;publisherName=SpringerNature&amp;orderBeanReset=true&amp;oa=CC%20BY">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info" data-title="About this article"><div class="c-article-section" id="article-info-section"><h2 class="c-article-section__title js-section-title js-c-reading-companion-sections-item" id="article-info">About this article</h2><div class="c-article-section__content" id="article-info-content"><div class="c-bibliographic-information"><div class="u-hide-print c-bibliographic-information__column c-bibliographic-information__column--border"><a data-crossmark="10.1007/s10898-019-00767-0" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1007/s10898-019-00767-0" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img width="57" height="81" alt="Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>" /></a></div><div class="c-bibliographic-information__column"><h3 class="c-article__sub-heading" id="citeas">Cite this article</h3><p class="c-bibliographic-information__citation">Schlegel, K. When is there a representer theorem?.
                    <i>J Glob Optim</i> <b>74, </b>401–415 (2019). https://doi.org/10.1007/s10898-019-00767-0</p><p class="c-bibliographic-information__download-citation u-hide-print"><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" href="/article/10.1007/s10898-019-00767-0.ris">Download citation<svg width="16" height="16" class="u-icon"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul class="c-bibliographic-information__list" data-test="publication-history"><li class="c-bibliographic-information__list-item"><p>Received<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2018-07-25">25 July 2018</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Accepted<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2019-03-28">28 March 2019</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Published<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2019-04-08">08 April 2019</time></span></p></li><li class="c-bibliographic-information__list-item"><p>Issue Date<span class="u-hide">: </span><span class="c-bibliographic-information__value"><time datetime="2019-06-15">15 June 2019</time></span></p></li><li class="c-bibliographic-information__list-item c-bibliographic-information__list-item--doi"><p><abbr title="Digital Object Identifier">DOI</abbr><span class="u-hide">: </span><span class="c-bibliographic-information__value"><a href="https://doi.org/10.1007/s10898-019-00767-0" data-track="click" data-track-action="view doi" data-track-label="link" itemprop="sameAs">https://doi.org/10.1007/s10898-019-00767-0</a></span></p></li></ul><div data-component="share-box"></div><h3 class="c-article__sub-heading">Keywords</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span itemprop="about">Representer theorem</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Regularised interpolation</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Regularisation</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Semi-inner product spaces</span></li><li class="c-article-subject-list__subject"><span itemprop="about">Kernel methods</span></li></ul><h3 class="c-article__sub-heading">Mathematics Subject Classification</h3><ul class="c-article-subject-list"><li class="c-article-subject-list__subject"><span itemprop="about">68T05</span></li></ul><div data-component="article-info-list"></div></div></div></div></div></section>
                </div>
            </article>
        </main>

        <div class="c-article-extras u-text-sm u-hide-print" id="sidebar" data-container-type="reading-companion" data-track-component="reading companion">
            <aside>
                <div data-test="download-article-link-wrapper">
                    
    <div class="c-pdf-download u-clear-both">
        <a href="https://link.springer.com/content/pdf/10.1007/s10898-019-00767-0.pdf" class="c-pdf-download__link" data-article-pdf="true" data-readcube-pdf-url="true" data-test="pdf-link" data-draft-ignore="true" data-track="click" data-track-action="download pdf" data-track-label="button" download>
            
                <span>Download PDF</span>
                <svg aria-hidden="true" focusable="false" width="16" height="16" class="u-icon"><use xlink:href="#global-icon-download"/></svg>
            
        </a>
    </div>

                </div>

                <div data-test="collections">
                    <div id="SpringerLinkArticleCollections">
    
</div>

                </div>

                <div data-test="editorial-summary">
                    
                </div>

                <div class="c-reading-companion">
                    <div class="c-reading-companion__sticky" data-component="reading-companion-sticky" data-test="reading-companion-sticky">
                        

                        <div class="c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active" id="tabpanel-sections">
                            <div class="js-ad">
    <aside class="c-ad c-ad--300x250">
        <div class="c-ad__inner">
            <p class="c-ad__label">Advertisement</p>
            <div id="div-gpt-ad-MPU1" data-gpt-unitpath="/270604982/springerlink/10898/article" data-gpt-sizes="300x250" data-gpt-targeting="pos=MPU1;articleid=767;"></div>
        </div>
    </aside>
</div>

                        </div>
                        <div class="c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width" id="tabpanel-figures"></div>
                        <div class="c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width" id="tabpanel-references"></div>
                    </div>
                </div>
            </aside>
        </div>
    </div>


        
    <footer class="app-footer" role="contentinfo">
        <div class="app-footer__aside-wrapper u-hide-print">
            <div class="app-footer__container">
                <p class="app-footer__strapline">Over 10 million scientific documents at your fingertips</p>
                
                    <div class="app-footer__edition" data-component="SV.EditionSwitcher">
                        <span class="u-visually-hidden" data-role="button-dropdown__title" data-btn-text="Switch between Academic & Corporate Edition">Switch Edition</span>
                        <ul class="app-footer-edition-list" data-role="button-dropdown__content" data-test="footer-edition-switcher-list">
                            <li class="selected">
                                <a data-test="footer-academic-link"
                                   href="/siteEdition/link"
                                   id="siteedition-academic-link">Academic Edition</a>
                            </li>
                            <li>
                                <a data-test="footer-corporate-link"
                                   href="/siteEdition/rd"
                                   id="siteedition-corporate-link">Corporate Edition</a>
                            </li>
                        </ul>
                    </div>
                
            </div>
        </div>
        <div class="app-footer__container">
            <ul class="app-footer__nav u-hide-print">
                <li><a href="/">Home</a></li>
                <li><a href="/impressum">Impressum</a></li>
                <li><a href="/termsandconditions">Legal information</a></li>
                <li><a href="/privacystatement">Privacy statement</a></li>
                <li><a href="https://www.springernature.com/ccpa">California Privacy Statement</a></li>
                <li><a href="/cookiepolicy">How we use cookies</a></li>
                
                <li><a class="optanon-toggle-display" href="javascript:void(0);">Manage cookies/Do not sell my data</a></li>
                
                <li><a href="/accessibility">Accessibility</a></li>
                <li><a id="contactus-footer-link" href="/contactus">Contact us</a></li>
            </ul>
            <div class="c-user-metadata">
    
        <p class="c-user-metadata__item">
            <span data-test="footer-user-login-status">Not logged in</span>
            <span data-test="footer-user-ip"> - 82.48.51.198</span>
        </p>
        <p class="c-user-metadata__item" data-test="footer-business-partners">
            Not affiliated
        </p>

        
    
</div>

            <a class="app-footer__parent-logo" target="_blank" rel="noopener" href="//www.springernature.com"  title="Go to Springer Nature">
                <span class="u-visually-hidden">Springer Nature</span>
                <svg width="125" height="12" focusable="false" aria-hidden="true">
                    <image width="125" height="12" alt="Springer Nature logo"
                           src=/oscar-static/images/springerlink/png/springernature-60a72a849b.png
                           xmlns:xlink="http://www.w3.org/1999/xlink"
                           xlink:href=/oscar-static/images/springerlink/svg/springernature-ecf01c77dd.svg>
                    </image>
                </svg>
            </a>
            <p class="app-footer__copyright">&copy; 2020 Springer Nature Switzerland AG. Part of <a target="_blank" rel="noopener" href="//www.springernature.com">Springer Nature</a>.</p>
            
        </div>
        
    <svg class="u-hide hide">
        <symbol id="global-icon-chevron-right" viewBox="0 0 16 16">
            <path d="M7.782 7L5.3 4.518c-.393-.392-.4-1.022-.02-1.403a1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L7.782 9l1.013-.998z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-download" viewBox="0 0 16 16">
            <path d="M2 14c0-.556.449-1 1.002-1h9.996a.999.999 0 110 2H3.002A1.006 1.006 0 012 14zM9 2v6.8l2.482-2.482c.392-.392 1.022-.4 1.403-.02a1.001 1.001 0 010 1.417l-4.177 4.177a1.001 1.001 0 01-1.416 0L3.115 7.715a.991.991 0 01-.016-1.4 1 1 0 011.42.003L7 8.8V2c0-.55.444-.996 1-.996.552 0 1 .445 1 .996z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-email" viewBox="0 0 18 18">
            <path d="M1.995 2h14.01A2 2 0 0118 4.006v9.988A2 2 0 0116.005 16H1.995A2 2 0 010 13.994V4.006A2 2 0 011.995 2zM1 13.994A1 1 0 001.995 15h14.01A1 1 0 0017 13.994V4.006A1 1 0 0016.005 3H1.995A1 1 0 001 4.006zM9 11L2 7V5.557l7 4 7-4V7z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-institution" viewBox="0 0 18 18">
            <path d="M14 8a1 1 0 011 1v6h1.5a.5.5 0 01.5.5v.5h.5a.5.5 0 01.5.5V18H0v-1.5a.5.5 0 01.5-.5H1v-.5a.5.5 0 01.5-.5H3V9a1 1 0 112 0v6h8V9a1 1 0 011-1zM6 8l2 1v4l-2 1zm6 0v6l-2-1V9zM9.573.401l7.036 4.925A.92.92 0 0116.081 7H1.92a.92.92 0 01-.528-1.674L8.427.401a1 1 0 011.146 0zM9 2.441L5.345 5h7.31z" fill-rule="evenodd"/>
        </symbol>
        <symbol id="global-icon-search" viewBox="0 0 22 22">
            <path fill-rule="evenodd" d="M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z"/>
        </symbol>
        <symbol id="icon-info" viewBox="0 0 18 18">
            <path d="m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm0 7h-1.5l-.11662113.00672773c-.49733868.05776511-.88337887.48043643-.88337887.99327227 0 .47338693.32893365.86994729.77070917.97358929l.1126697.01968298.11662113.00672773h.5v3h-.5l-.11662113.0067277c-.42082504.0488782-.76196299.3590206-.85696816.7639815l-.01968298.1126697-.00672773.1166211.00672773.1166211c.04887817.4208251.35902055.761963.76398144.8569682l.1126697.019683.11662113.0067277h3l.1166211-.0067277c.4973387-.0577651.8833789-.4804365.8833789-.9932723 0-.4733869-.3289337-.8699473-.7707092-.9735893l-.1126697-.019683-.1166211-.0067277h-.5v-4l-.00672773-.11662113c-.04887817-.42082504-.35902055-.76196299-.76398144-.85696816l-.1126697-.01968298zm0-3.25c-.69035594 0-1.25.55964406-1.25 1.25s.55964406 1.25 1.25 1.25 1.25-.55964406 1.25-1.25-.55964406-1.25-1.25-1.25z" fill-rule="evenodd"/>
        </symbol>
    </svg>

    </footer>



    </div>
    
    
</body>
</html>

